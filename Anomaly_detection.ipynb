{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3959122b",
   "metadata": {},
   "source": [
    "# Anomaly detection in energy storage systems."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52999b83",
   "metadata": {},
   "source": [
    "# Overview\n",
    "Renewable energy sources have become one of the significant factors contributing to new energy generation construction.\n",
    "\n",
    "One of the critical components of renewables is Energy Storage Systems that allow to conserve energy during peak production hours and release it when energy generation is limited. This helps to solve the problem of stability of energy generation from renewable sources of energy.\n",
    "\n",
    "Safety is a critical question for Energy storage systems. Failure of one cell leads to a thermal runaway that results in the unstoppable chemical fire inside Energy Storage System that results in complete site destruction. https://www.spglobal.com/marketintelligence/en/news-insights/latest-news-headlines/burning-concern-energy-storage-industry-battles-battery-fires-51900636\n",
    "\n",
    "While system failure can't be predicted because it depends on many factors, including cell internal structure damages, some factors contribute to it. \n",
    "\n",
    "Some of them:\n",
    "\n",
    "- avoiding over-discharge and overcharge of batteries\n",
    "\n",
    "- control of cell temperature.\n",
    "\n",
    "One of the challenges is that the Energy Storage system consists of hundreds of thousands of cells, each with a temperature and voltage sensor that generates an enormous amount of information. For example, https://pv-magazine-usa.com/2022/02/15/mce-approves-100mw-solar-plus-storage-project-in-california/ \n",
    "This project capacity is 75MWh It will require installation of at least 190 000 battery cells (up to 500 000 depends on technology that will be used) each of them will provide information about their status.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Business Understanding\n",
    "Our stakeholder wants to have a model that can analyze the status of 10 000+ cells during commissioning and annual service works. This model should identify abnormal behavior of cells that can lead to hazards during further operations.\n",
    "\n",
    "Abnormal behavior:\n",
    "\n",
    "Too low/high voltage sensors readings.\n",
    "\n",
    "Too low/high-temperature sensor readings\n",
    "\n",
    "Current imbalance during charge/discharge.\n",
    "\n",
    "Our model should accept raw data provided from BMS(Battery management system) systems manufactured by BMester (one of the key suppliers).\n",
    "\n",
    "The model should be easy to use and interpret results by commissioning engineers.\n",
    "\n",
    "# Data\n",
    "\n",
    "1) Sensor readings that weere taken from 5 cluster systems taken in June 2021 during commissioning works.\n",
    "\n",
    "\n",
    "# Metrics\n",
    "#### Our project will answer following question:\n",
    "Can we forecast sensor readings limits and automatically identify cells that are out of limits for further investigation. \n",
    "\n",
    "#### Hypothesis:\n",
    "H0 - Anomaly in cell\n",
    "\n",
    "HA - There is statistically significant proof that there is no anomaly in the cell.\n",
    "\n",
    "#### TP, TN, FP, FN definition\n",
    "\n",
    "TP - We predicted anomaly, and it does exist\n",
    "\n",
    "TN - We predicted that there is no anomaly and it doesn't exist\n",
    "\n",
    "FP - We predicted an anomaly, but there was no anomaly.\n",
    "\n",
    "FN - We predicted that there is no anomaly,  but it existed.\n",
    "\n",
    "\n",
    "#### Metrics used  \n",
    "To compare models, we will focus on two primary metrics:\n",
    "\n",
    "Recall - Missing any anomaly case can lead to Hazard. Therefore, we are focused on finding as much as possible.\n",
    "\n",
    "Accuracy - how well we can predict TP and TN. These are general metrics that will show model performance.\n",
    "\n",
    "##### While it is impossible to say that the actual identified case will lead to Hazard, it is crucial to find and mark cells for further investigation of service engineers.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcdcd20",
   "metadata": {},
   "source": [
    "\n",
    "# Data Understanding\n",
    "#### Sources of data:\n",
    "1) Chest X-Ray Images. Year: 2018 \n",
    "Kermany, Daniel; Zhang, Kang; Goldbaum, Michael (2018), “Large Dataset of Labeled Optical Coherence Tomography (OCT) and Chest X-Ray Images”, Mendeley Data, V3, doi: 10.17632/rscbjbr9sj.3\n",
    "\n",
    "https://data.mendeley.com/datasets/rscbjbr9sj/3\n",
    "\n",
    "#### Main dataset contains the following images:\n",
    "Train set:\n",
    "\n",
    "There are 1349 normal images, image name example, NORMAL-2552119-0002.jpeg\n",
    "\n",
    "There are 4489 pneumonia images, image name example, BACTERIA-4038442-0001.jpeg\n",
    "\n",
    "Test set:\n",
    "\n",
    "There are 234 normal images, image name example, NORMAL-8698006-0001.jpeg\n",
    "\n",
    "There are 390 pneumonia images, image name example, VIRUS-2040583-0001.jpeg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24102ee3",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "### Importing required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b0985f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import os\n",
    "import re\n",
    "#import cv2\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Work with data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualizations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "\n",
    "\n",
    "#Modeling\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, classification_report, roc_curve, plot_roc_curve, roc_auc_score, accuracy_score, recall_score, f1_score\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.regularizers import l2\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras import layers\n",
    "from keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Other\n",
    "import pickle\n",
    "import time\n",
    "import os, shutil \n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import itertools\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "#import cv2\n",
    "\n",
    "# from warnings import simplefilter\n",
    "# from sklearn.exceptions import ConvergenceWarning, FitFailedWarning\n",
    "# simplefilter(action='ignore', category= FutureWarning)\n",
    "# simplefilter(action='ignore', category= ConvergenceWarning)\n",
    "# simplefilter(action='ignore', category= FitFailedWarning)\n",
    "# simplefilter(action='ignore', category= UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9508df54",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc17371",
   "metadata": {},
   "source": [
    "Below we create three objects representing the existing directories: `data/normal/` as `data_normal_dir` and `data/pneumonia/` as `data_pneumonia_dir`, `data/test/normal/` as `test/normal` and `data/test/pneumonia/` as `test/pneumonia`. We will create a new directory `split/` as `new_dir`, where we will split the dataset in three groups (or three subdirectories): `train`, `test`, and `validation`, each containing `normal` and `pneumonia` subfolders. The final desired structure is represented below: \n",
    "\n",
    "![title](images/folder_structure.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efa9fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "class config:\n",
    "    def __init__(self):\n",
    "        self.low_voltage_th = -3\n",
    "        self.low_voltage_alarm = -2\n",
    "        self.high_voltage_th = 3\n",
    "        self.high_voltage_alarm = 2\n",
    "        self.low_temperature = 100\n",
    "        self.high_temperature = 100\n",
    "        self.high_mean_temperature_alarm = 400\n",
    "        self.low_mean_temperature_alarm = 50\n",
    "        self.low_voltage_n_std = 3\n",
    "        self.low_voltage_alarm_n_std = 2\n",
    "        self.high_voltage_n_std = 3\n",
    "        self.high_voltage_alarm_n_std = 2\n",
    "        self.sensor_v_prec = 5\n",
    "        self.period_h = 12\n",
    "\n",
    "\n",
    "# low_voltage_th = -3\n",
    "# low_voltage_alarm = -2\n",
    "# high_voltage_th = 3\n",
    "# high_voltage_alarm = 2\n",
    "# low_temperature = 100\n",
    "# high_temperature = 100\n",
    "# high_mean_temperature_alarm = 400\n",
    "# low_mean_temperature_alarm = 50\n",
    "conf = config()\n",
    "sns.set_style(\"whitegrid\")\n",
    "markers = [\"*\", \"<\", \"v\",\"^\",\"p\",\">\",\"s\",\"p\",\"o\", \"*\", \"<\", \"v\",\"^\",\"p\",\">\",\"s\",\"p\" ]\n",
    "cmap = plt.get_cmap('Dark2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "936dc0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data folder\n",
    "raw_folder = \"raw/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61f2bca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files inside\n",
    "files = [file for file in os.listdir(raw_folder) if file.endswith(\"csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c62efa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir(raw_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac193d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['raw/vol1 20210610 19.csv',\n",
       " 'raw/vol1 20210610 18.csv',\n",
       " 'raw/vol1 20210610 17.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make list of paths\n",
    "list_paths = [raw_folder + file for file in files]\n",
    "list_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "543466e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create timeseries from files inside the folder\n",
    "def create_dataframe(list_paths, df_type = \"voltage\", resample_time= \"30S\"):\n",
    "    # read\n",
    "    files = [list_paths + file for file in os.listdir(list_paths) if file.endswith(\"csv\")]\n",
    "    df_type = df_type.lower()\n",
    "    reg = re.compile(df_type)\n",
    "    dataframe = [pd.read_csv(file) for file in files]\n",
    "    final_df = pd.concat(dataframe, axis = 0)\n",
    "    final_df[\"MCGS_TIME\"] = pd.to_datetime(final_df[\"MCGS_TIME\"])\n",
    "    final_df = final_df.set_index(\"MCGS_TIME\")\n",
    "    drop_columns = [column for column in final_df.columns.str.lower() if not bool(re.match(reg, column))]\n",
    "    final_df.columns = final_df.columns.str.lower()\n",
    "    final_df= final_df.drop(drop_columns, axis = 1)\n",
    "    final_df = final_df.resample(resample_time).mean().bfill()\n",
    "    return final_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "629e0aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe = [pd.read_csv(path) for path in list_paths]\n",
    "# final_df = pd.concat(dataframe, axis = 0)\n",
    "# final_df[\"MCGS_TIME\"] = pd.to_datetime(final_df[\"MCGS_TIME\"])\n",
    "# final_df = final_df.set_index(\"MCGS_TIME\")\n",
    "# drop_columns = [column for column in final_df.columns.str.lower() if \"voltage\" not in column]\n",
    "# # final_df= final_df.drop(drop_columns, axis = 1)\n",
    "# # final_df = final_df.resample(\"30S\").mean().bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5db006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1af66912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find clusters\n",
    "# clusters = [cluster for cluster in os.listdir(raw_folder) if \"cluster\" in cluster]\n",
    "# # Prepare path for each cluster\n",
    "# clusters_paths = [(raw_folder + cluster + \"/\", cluster) for cluster in clusters]\n",
    "# # Check data sources in each cluster\n",
    "# os.listdir(clusters_path[0][0])\n",
    "# # Divide it cluster to different types of data\n",
    "# voltage_paths = [(cluster_parth[0]+\"voltage/\", cluster_parth[1]) for cluster_parth in clusters_paths]\n",
    "# temperature_paths = [(cluster_parth[0]+\"temperature/\", cluster_parth[1]) for cluster_parth in clusters_paths]\n",
    "# state_paths = [(cluster_parth[0]+\"total state/\", cluster_parth[1]) for cluster_parth in clusters_paths]\n",
    "\n",
    "# # Create datasets\n",
    "# df_voltage_list = [create_dataframe(voltage_path[0], \"[a-zA-Z0-9_]+voltage\") for voltage_path in voltage_paths]\n",
    "# df_temperature_list = [create_dataframe(temperature_path[0], '[a-zA-Z0-9_]+temperature') for temperature_path in temperature_paths]\n",
    "# df_state_list = [create_dataframe(state_path[0], '[a-zA-Z0-9_]+current$') for state_path in state_paths]\n",
    "\n",
    "# # Check that all datasets in clusters\n",
    "# assert len(df_voltage_list) == len(df_temperature_list)\n",
    "# assert len(df_voltage_list) == len(df_state_list)\n",
    "\n",
    "# # Check that same timeframes\n",
    "# for i in range(len(df_voltage_list)):\n",
    "#     assert all(df_voltage_list[i].index == df_temperature_list[i].index)\n",
    "# #    assert all(df_30sec.index == df_30sec_temperature.index)\n",
    "\n",
    "# result_list = []\n",
    "\n",
    "# for i in range(len(df_voltage_list)):\n",
    "#     final = pd.concat([df_voltage_list[i], df_temperature_list[i], df_state_list[i]], axis = 1)\n",
    "#     result_list.append(final)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e9d9ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(raw_folder):\n",
    "    # Find clusters\n",
    "    clusters = [cluster for cluster in os.listdir(raw_folder) if \"cluster\" in cluster]\n",
    "    # Prepare path for each cluster\n",
    "    clusters_paths = [(raw_folder + cluster + \"/\", cluster) for cluster in clusters]\n",
    "    \n",
    "    # Divide it cluster to different types of data\n",
    "    voltage_paths = [(cluster_parth[0]+\"voltage/\", cluster_parth[1]) for cluster_parth in clusters_paths]\n",
    "    temperature_paths = [(cluster_parth[0]+\"temperature/\", cluster_parth[1]) for cluster_parth in clusters_paths]\n",
    "    state_paths = [(cluster_parth[0]+\"total state/\", cluster_parth[1]) for cluster_parth in clusters_paths]\n",
    "\n",
    "    # Concat data\n",
    "    df_voltage_list = [create_dataframe(voltage_path[0], \"[a-zA-Z0-9_]+voltage\") for voltage_path in voltage_paths]\n",
    "    df_temperature_list = [create_dataframe(temperature_path[0], '[a-zA-Z0-9_]+temperature') for temperature_path in temperature_paths]\n",
    "    df_state_list = [create_dataframe(state_path[0], '[a-zA-Z0-9_]+current$') for state_path in state_paths]\n",
    "\n",
    "    # Check that all datasets in clusters\n",
    "    assert len(df_voltage_list) == len(df_temperature_list)\n",
    "    assert len(df_voltage_list) == len(df_state_list)\n",
    "\n",
    "    # Check that same timeframes\n",
    "    for i in range(len(df_voltage_list)):\n",
    "        print(df_voltage_list[i].index)\n",
    "        print(df_temperature_list[i].index)\n",
    "        assert all(df_voltage_list[i].index == df_temperature_list[i].index)\n",
    "    #    assert all(df_30sec.index == df_30sec_temperature.index)\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "    for i in range(len(df_voltage_list)):\n",
    "        final = pd.concat([df_voltage_list[i], df_temperature_list[i], df_state_list[i]], axis = 1).dropna()\n",
    "        result_list.append(final)\n",
    "    print(f\"Number of Clusters were found: {len(result_list)}\")\n",
    "    return result_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2de6d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2021-06-10 17:00:00', '2021-06-10 17:00:30',\n",
      "               '2021-06-10 17:01:00', '2021-06-10 17:01:30',\n",
      "               '2021-06-10 17:02:00', '2021-06-10 17:02:30',\n",
      "               '2021-06-10 17:03:00', '2021-06-10 17:03:30',\n",
      "               '2021-06-10 17:04:00', '2021-06-10 17:04:30',\n",
      "               ...\n",
      "               '2021-06-10 19:55:00', '2021-06-10 19:55:30',\n",
      "               '2021-06-10 19:56:00', '2021-06-10 19:56:30',\n",
      "               '2021-06-10 19:57:00', '2021-06-10 19:57:30',\n",
      "               '2021-06-10 19:58:00', '2021-06-10 19:58:30',\n",
      "               '2021-06-10 19:59:00', '2021-06-10 19:59:30'],\n",
      "              dtype='datetime64[ns]', name='MCGS_TIME', length=360, freq='30S')\n",
      "DatetimeIndex(['2021-06-10 17:00:00', '2021-06-10 17:00:30',\n",
      "               '2021-06-10 17:01:00', '2021-06-10 17:01:30',\n",
      "               '2021-06-10 17:02:00', '2021-06-10 17:02:30',\n",
      "               '2021-06-10 17:03:00', '2021-06-10 17:03:30',\n",
      "               '2021-06-10 17:04:00', '2021-06-10 17:04:30',\n",
      "               ...\n",
      "               '2021-06-10 19:55:00', '2021-06-10 19:55:30',\n",
      "               '2021-06-10 19:56:00', '2021-06-10 19:56:30',\n",
      "               '2021-06-10 19:57:00', '2021-06-10 19:57:30',\n",
      "               '2021-06-10 19:58:00', '2021-06-10 19:58:30',\n",
      "               '2021-06-10 19:59:00', '2021-06-10 19:59:30'],\n",
      "              dtype='datetime64[ns]', name='MCGS_TIME', length=360, freq='30S')\n",
      "DatetimeIndex(['2021-06-10 20:00:00', '2021-06-10 20:00:30',\n",
      "               '2021-06-10 20:01:00', '2021-06-10 20:01:30',\n",
      "               '2021-06-10 20:02:00', '2021-06-10 20:02:30',\n",
      "               '2021-06-10 20:03:00', '2021-06-10 20:03:30',\n",
      "               '2021-06-10 20:04:00', '2021-06-10 20:04:30',\n",
      "               ...\n",
      "               '2021-06-11 01:55:00', '2021-06-11 01:55:30',\n",
      "               '2021-06-11 01:56:00', '2021-06-11 01:56:30',\n",
      "               '2021-06-11 01:57:00', '2021-06-11 01:57:30',\n",
      "               '2021-06-11 01:58:00', '2021-06-11 01:58:30',\n",
      "               '2021-06-11 01:59:00', '2021-06-11 01:59:30'],\n",
      "              dtype='datetime64[ns]', name='MCGS_TIME', length=720, freq='30S')\n",
      "DatetimeIndex(['2021-06-10 20:00:00', '2021-06-10 20:00:30',\n",
      "               '2021-06-10 20:01:00', '2021-06-10 20:01:30',\n",
      "               '2021-06-10 20:02:00', '2021-06-10 20:02:30',\n",
      "               '2021-06-10 20:03:00', '2021-06-10 20:03:30',\n",
      "               '2021-06-10 20:04:00', '2021-06-10 20:04:30',\n",
      "               ...\n",
      "               '2021-06-11 01:55:00', '2021-06-11 01:55:30',\n",
      "               '2021-06-11 01:56:00', '2021-06-11 01:56:30',\n",
      "               '2021-06-11 01:57:00', '2021-06-11 01:57:30',\n",
      "               '2021-06-11 01:58:00', '2021-06-11 01:58:30',\n",
      "               '2021-06-11 01:59:00', '2021-06-11 01:59:30'],\n",
      "              dtype='datetime64[ns]', name='MCGS_TIME', length=720, freq='30S')\n",
      "Number of Clusters were found: 2\n"
     ]
    }
   ],
   "source": [
    "raw_folder = \"raw/\"\n",
    "result_list = data_preprocess(raw_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a017518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find cell voltage, temperature, state columns\n",
    "voltage_columns = [column for column in result_list[0].columns if bool(re.match(re.compile(\"[a-zA-Z0-9_]+voltage\"), column))]\n",
    "temperatrue_columns = [column for column in result_list[0].columns if bool(re.match(re.compile('[a-zA-Z0-9_]+temperature'), column))]\n",
    "state_column = [column for column in result_list[0].columns if bool(re.match(re.compile('[a-zA-Z0-9_]+current$'), column))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7ca8dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                     cluster_1_cellvoltage_001  cluster_1_cellvoltage_002  \\\n",
       " MCGS_TIME                                                                   \n",
       " 2021-06-10 17:00:00                3256.000000                3256.000000   \n",
       " 2021-06-10 17:00:30                3256.000000                3256.000000   \n",
       " 2021-06-10 17:01:00                3256.000000                3256.000000   \n",
       " 2021-06-10 17:01:30                3256.000000                3256.000000   \n",
       " 2021-06-10 17:02:00                3256.000000                3256.000000   \n",
       " ...                                        ...                        ...   \n",
       " 2021-06-10 19:57:30                3383.666667                3386.000000   \n",
       " 2021-06-10 19:58:00                3385.333333                3387.333333   \n",
       " 2021-06-10 19:58:30                3386.333333                3388.333333   \n",
       " 2021-06-10 19:59:00                3387.666667                3389.666667   \n",
       " 2021-06-10 19:59:30                3388.666667                3390.666667   \n",
       " \n",
       "                      cluster_1_cellvoltage_003  cluster_1_cellvoltage_004  \\\n",
       " MCGS_TIME                                                                   \n",
       " 2021-06-10 17:00:00                3256.000000                3256.000000   \n",
       " 2021-06-10 17:00:30                3256.000000                3256.000000   \n",
       " 2021-06-10 17:01:00                3256.000000                3256.000000   \n",
       " 2021-06-10 17:01:30                3256.000000                3256.000000   \n",
       " 2021-06-10 17:02:00                3256.000000                3256.000000   \n",
       " ...                                        ...                        ...   \n",
       " 2021-06-10 19:57:30                3383.000000                3391.000000   \n",
       " 2021-06-10 19:58:00                3384.333333                3392.000000   \n",
       " 2021-06-10 19:58:30                3385.333333                3393.333333   \n",
       " 2021-06-10 19:59:00                3386.666667                3394.000000   \n",
       " 2021-06-10 19:59:30                3388.000000                3395.666667   \n",
       " \n",
       "                      cluster_1_cellvoltage_005  cluster_1_cellvoltage_006  \\\n",
       " MCGS_TIME                                                                   \n",
       " 2021-06-10 17:00:00                3256.000000                3258.000000   \n",
       " 2021-06-10 17:00:30                3256.000000                3258.000000   \n",
       " 2021-06-10 17:01:00                3256.000000                3258.000000   \n",
       " 2021-06-10 17:01:30                3256.000000                3258.000000   \n",
       " 2021-06-10 17:02:00                3256.000000                3258.000000   \n",
       " ...                                        ...                        ...   \n",
       " 2021-06-10 19:57:30                3387.333333                3383.333333   \n",
       " 2021-06-10 19:58:00                3388.666667                3384.666667   \n",
       " 2021-06-10 19:58:30                3389.666667                3385.333333   \n",
       " 2021-06-10 19:59:00                3391.000000                3386.666667   \n",
       " 2021-06-10 19:59:30                3392.333333                3388.000000   \n",
       " \n",
       "                      cluster_1_cellvoltage_007  cluster_1_cellvoltage_008  \\\n",
       " MCGS_TIME                                                                   \n",
       " 2021-06-10 17:00:00                3258.000000                3257.000000   \n",
       " 2021-06-10 17:00:30                3258.000000                3257.000000   \n",
       " 2021-06-10 17:01:00                3258.000000                3257.000000   \n",
       " 2021-06-10 17:01:30                3258.000000                3257.000000   \n",
       " 2021-06-10 17:02:00                3258.000000                3257.000000   \n",
       " ...                                        ...                        ...   \n",
       " 2021-06-10 19:57:30                3385.000000                3379.666667   \n",
       " 2021-06-10 19:58:00                3386.333333                3381.333333   \n",
       " 2021-06-10 19:58:30                3387.666667                3382.333333   \n",
       " 2021-06-10 19:59:00                3388.666667                3383.333333   \n",
       " 2021-06-10 19:59:30                3389.666667                3384.666667   \n",
       " \n",
       "                      cluster_1_cellvoltage_009  cluster_1_cellvoltage_010  \\\n",
       " MCGS_TIME                                                                   \n",
       " 2021-06-10 17:00:00                3257.000000                3258.000000   \n",
       " 2021-06-10 17:00:30                3257.000000                3258.000000   \n",
       " 2021-06-10 17:01:00                3257.000000                3258.000000   \n",
       " 2021-06-10 17:01:30                3257.000000                3258.000000   \n",
       " 2021-06-10 17:02:00                3257.000000                3258.000000   \n",
       " ...                                        ...                        ...   \n",
       " 2021-06-10 19:57:30                3384.666667                3384.333333   \n",
       " 2021-06-10 19:58:00                3386.333333                3386.000000   \n",
       " 2021-06-10 19:58:30                3387.333333                3386.666667   \n",
       " 2021-06-10 19:59:00                3388.666667                3388.000000   \n",
       " 2021-06-10 19:59:30                3389.666667                3389.000000   \n",
       " \n",
       "                      ...  cluster_1_temperature_232  \\\n",
       " MCGS_TIME            ...                              \n",
       " 2021-06-10 17:00:00  ...                      229.0   \n",
       " 2021-06-10 17:00:30  ...                      229.0   \n",
       " 2021-06-10 17:01:00  ...                      229.0   \n",
       " 2021-06-10 17:01:30  ...                      229.0   \n",
       " 2021-06-10 17:02:00  ...                      229.0   \n",
       " ...                  ...                        ...   \n",
       " 2021-06-10 19:57:30  ...                      268.0   \n",
       " 2021-06-10 19:58:00  ...                      269.0   \n",
       " 2021-06-10 19:58:30  ...                      269.0   \n",
       " 2021-06-10 19:59:00  ...                      270.0   \n",
       " 2021-06-10 19:59:30  ...                      271.0   \n",
       " \n",
       "                      cluster_1_temperature_233  cluster_1_temperature_234  \\\n",
       " MCGS_TIME                                                                   \n",
       " 2021-06-10 17:00:00                      228.0                      227.0   \n",
       " 2021-06-10 17:00:30                      228.0                      227.0   \n",
       " 2021-06-10 17:01:00                      228.0                      227.0   \n",
       " 2021-06-10 17:01:30                      228.0                      227.0   \n",
       " 2021-06-10 17:02:00                      228.0                      227.0   \n",
       " ...                                        ...                        ...   \n",
       " 2021-06-10 19:57:30                      272.0                      276.0   \n",
       " 2021-06-10 19:58:00                      273.0                      276.0   \n",
       " 2021-06-10 19:58:30                      274.0                      277.0   \n",
       " 2021-06-10 19:59:00                      274.0                      278.0   \n",
       " 2021-06-10 19:59:30                      275.0                      279.0   \n",
       " \n",
       "                      cluster_1_temperature_235  cluster_1_temperature_236  \\\n",
       " MCGS_TIME                                                                   \n",
       " 2021-06-10 17:00:00                      220.0                      210.0   \n",
       " 2021-06-10 17:00:30                      220.0                      210.0   \n",
       " 2021-06-10 17:01:00                      220.0                      210.0   \n",
       " 2021-06-10 17:01:30                      220.0                      210.0   \n",
       " 2021-06-10 17:02:00                      220.0                      210.0   \n",
       " ...                                        ...                        ...   \n",
       " 2021-06-10 19:57:30                      274.0                      273.0   \n",
       " 2021-06-10 19:58:00                      275.0                      274.0   \n",
       " 2021-06-10 19:58:30                      276.0                      274.0   \n",
       " 2021-06-10 19:59:00                      276.0                      275.0   \n",
       " 2021-06-10 19:59:30                      277.0                      276.0   \n",
       " \n",
       "                      cluster_1_temperature_237  cluster_1_temperature_238  \\\n",
       " MCGS_TIME                                                                   \n",
       " 2021-06-10 17:00:00                      197.0                      188.0   \n",
       " 2021-06-10 17:00:30                      197.0                      188.0   \n",
       " 2021-06-10 17:01:00                      197.0                      188.0   \n",
       " 2021-06-10 17:01:30                      197.0                      188.0   \n",
       " 2021-06-10 17:02:00                      197.0                      188.0   \n",
       " ...                                        ...                        ...   \n",
       " 2021-06-10 19:57:30                      269.0                      271.0   \n",
       " 2021-06-10 19:58:00                      269.0                      272.0   \n",
       " 2021-06-10 19:58:30                      270.0                      272.0   \n",
       " 2021-06-10 19:59:00                      271.0                      273.0   \n",
       " 2021-06-10 19:59:30                      272.0                      274.0   \n",
       " \n",
       "                      cluster_1_temperature_239  cluster_1_temperature_240  \\\n",
       " MCGS_TIME                                                                   \n",
       " 2021-06-10 17:00:00                      194.0                      204.0   \n",
       " 2021-06-10 17:00:30                      194.0                      204.0   \n",
       " 2021-06-10 17:01:00                      194.0                      204.0   \n",
       " 2021-06-10 17:01:30                      194.0                      204.0   \n",
       " 2021-06-10 17:02:00                      194.0                      204.0   \n",
       " ...                                        ...                        ...   \n",
       " 2021-06-10 19:57:30                      271.0                      271.0   \n",
       " 2021-06-10 19:58:00                      272.0                      272.0   \n",
       " 2021-06-10 19:58:30                      273.0                      272.0   \n",
       " 2021-06-10 19:59:00                      274.0                      273.0   \n",
       " 2021-06-10 19:59:30                      274.0                      274.0   \n",
       " \n",
       "                      cluster1_current  \n",
       " MCGS_TIME                              \n",
       " 2021-06-10 17:00:00          0.000000  \n",
       " 2021-06-10 17:00:30          0.000000  \n",
       " 2021-06-10 17:01:00          0.000000  \n",
       " 2021-06-10 17:01:30          0.000000  \n",
       " 2021-06-10 17:02:00          0.000000  \n",
       " ...                               ...  \n",
       " 2021-06-10 19:57:30      -1147.666667  \n",
       " 2021-06-10 19:58:00      -1146.666667  \n",
       " 2021-06-10 19:58:30      -1146.333333  \n",
       " 2021-06-10 19:59:00      -1147.000000  \n",
       " 2021-06-10 19:59:30      -1147.666667  \n",
       " \n",
       " [360 rows x 481 columns],\n",
       "                      cluster_2_cellvoltage_001  cluster_2_cellvoltage_002  \\\n",
       " MCGS_TIME                                                                   \n",
       " 2021-06-10 20:00:00                3393.666667                3392.666667   \n",
       " 2021-06-10 20:00:30                3394.666667                3393.666667   \n",
       " 2021-06-10 20:01:00                3395.333333                3394.666667   \n",
       " 2021-06-10 20:01:30                3396.333333                3395.333333   \n",
       " 2021-06-10 20:02:00                3397.000000                3396.000000   \n",
       " ...                                        ...                        ...   \n",
       " 2021-06-11 01:57:30                3335.333333                3337.000000   \n",
       " 2021-06-11 01:58:00                3335.000000                3337.000000   \n",
       " 2021-06-11 01:58:30                3335.000000                3337.000000   \n",
       " 2021-06-11 01:59:00                3335.000000                3337.000000   \n",
       " 2021-06-11 01:59:30                3335.000000                3337.000000   \n",
       " \n",
       "                      cluster_2_cellvoltage_003  cluster_2_cellvoltage_004  \\\n",
       " MCGS_TIME                                                                   \n",
       " 2021-06-10 20:00:00                3392.000000                3392.000000   \n",
       " 2021-06-10 20:00:30                3393.333333                3393.666667   \n",
       " 2021-06-10 20:01:00                3394.000000                3394.333333   \n",
       " 2021-06-10 20:01:30                3395.000000                3395.000000   \n",
       " 2021-06-10 20:02:00                3395.666667                3395.666667   \n",
       " ...                                        ...                        ...   \n",
       " 2021-06-11 01:57:30                3337.000000                3336.000000   \n",
       " 2021-06-11 01:58:00                3337.000000                3336.000000   \n",
       " 2021-06-11 01:58:30                3337.000000                3336.000000   \n",
       " 2021-06-11 01:59:00                3336.333333                3336.000000   \n",
       " 2021-06-11 01:59:30                3337.000000                3336.000000   \n",
       " \n",
       "                      cluster_2_cellvoltage_005  cluster_2_cellvoltage_006  \\\n",
       " MCGS_TIME                                                                   \n",
       " 2021-06-10 20:00:00                3389.666667                3392.000000   \n",
       " 2021-06-10 20:00:30                3390.666667                3393.333333   \n",
       " 2021-06-10 20:01:00                3391.666667                3394.333333   \n",
       " 2021-06-10 20:01:30                3392.333333                3395.000000   \n",
       " 2021-06-10 20:02:00                3393.000000                3395.666667   \n",
       " ...                                        ...                        ...   \n",
       " 2021-06-11 01:57:30                3337.000000                3336.000000   \n",
       " 2021-06-11 01:58:00                3337.000000                3336.000000   \n",
       " 2021-06-11 01:58:30                3337.000000                3336.000000   \n",
       " 2021-06-11 01:59:00                3337.000000                3336.000000   \n",
       " 2021-06-11 01:59:30                3337.000000                3336.000000   \n",
       " \n",
       "                      cluster_2_cellvoltage_007  cluster_2_cellvoltage_008  \\\n",
       " MCGS_TIME                                                                   \n",
       " 2021-06-10 20:00:00                3389.666667                3389.666667   \n",
       " 2021-06-10 20:00:30                3390.666667                3390.666667   \n",
       " 2021-06-10 20:01:00                3391.333333                3391.333333   \n",
       " 2021-06-10 20:01:30                3392.333333                3392.333333   \n",
       " 2021-06-10 20:02:00                3393.000000                3393.000000   \n",
       " ...                                        ...                        ...   \n",
       " 2021-06-11 01:57:30                3336.000000                3336.000000   \n",
       " 2021-06-11 01:58:00                3336.000000                3336.000000   \n",
       " 2021-06-11 01:58:30                3336.000000                3336.000000   \n",
       " 2021-06-11 01:59:00                3336.000000                3336.000000   \n",
       " 2021-06-11 01:59:30                3336.000000                3336.000000   \n",
       " \n",
       "                      cluster_2_cellvoltage_009  cluster_2_cellvoltage_010  \\\n",
       " MCGS_TIME                                                                   \n",
       " 2021-06-10 20:00:00                3390.000000                3392.000000   \n",
       " 2021-06-10 20:00:30                3391.000000                3393.000000   \n",
       " 2021-06-10 20:01:00                3391.333333                3393.666667   \n",
       " 2021-06-10 20:01:30                3392.333333                3394.333333   \n",
       " 2021-06-10 20:02:00                3393.000000                3395.000000   \n",
       " ...                                        ...                        ...   \n",
       " 2021-06-11 01:57:30                3335.000000                3336.000000   \n",
       " 2021-06-11 01:58:00                3335.000000                3336.000000   \n",
       " 2021-06-11 01:58:30                3335.000000                3336.333333   \n",
       " 2021-06-11 01:59:00                3335.000000                3336.000000   \n",
       " 2021-06-11 01:59:30                3335.000000                3336.000000   \n",
       " \n",
       "                      ...  cluster_2_temperature_232  \\\n",
       " MCGS_TIME            ...                              \n",
       " 2021-06-10 20:00:00  ...                      276.0   \n",
       " 2021-06-10 20:00:30  ...                      277.0   \n",
       " 2021-06-10 20:01:00  ...                      277.0   \n",
       " 2021-06-10 20:01:30  ...                      278.0   \n",
       " 2021-06-10 20:02:00  ...                      279.0   \n",
       " ...                  ...                        ...   \n",
       " 2021-06-11 01:57:30  ...                      294.0   \n",
       " 2021-06-11 01:58:00  ...                      294.0   \n",
       " 2021-06-11 01:58:30  ...                      293.0   \n",
       " 2021-06-11 01:59:00  ...                      293.0   \n",
       " 2021-06-11 01:59:30  ...                      292.0   \n",
       " \n",
       "                      cluster_2_temperature_233  cluster_2_temperature_234  \\\n",
       " MCGS_TIME                                                                   \n",
       " 2021-06-10 20:00:00                      273.0                      276.0   \n",
       " 2021-06-10 20:00:30                      274.0                      276.0   \n",
       " 2021-06-10 20:01:00                      275.0                      277.0   \n",
       " 2021-06-10 20:01:30                      276.0                      278.0   \n",
       " 2021-06-10 20:02:00                      276.0                      279.0   \n",
       " ...                                        ...                        ...   \n",
       " 2021-06-11 01:57:30                      283.0                      281.0   \n",
       " 2021-06-11 01:58:00                      282.0                      280.0   \n",
       " 2021-06-11 01:58:30                      282.0                      280.0   \n",
       " 2021-06-11 01:59:00                      281.0                      280.0   \n",
       " 2021-06-11 01:59:30                      281.0                      280.0   \n",
       " \n",
       "                      cluster_2_temperature_235  cluster_2_temperature_236  \\\n",
       " MCGS_TIME                                                                   \n",
       " 2021-06-10 20:00:00                      278.0                      277.0   \n",
       " 2021-06-10 20:00:30                      279.0                      277.0   \n",
       " 2021-06-10 20:01:00                      279.0                      278.0   \n",
       " 2021-06-10 20:01:30                      280.0                      279.0   \n",
       " 2021-06-10 20:02:00                      280.0                      279.0   \n",
       " ...                                        ...                        ...   \n",
       " 2021-06-11 01:57:30                      274.0                      255.0   \n",
       " 2021-06-11 01:58:00                      273.0                      254.0   \n",
       " 2021-06-11 01:58:30                      273.0                      254.0   \n",
       " 2021-06-11 01:59:00                      272.0                      253.0   \n",
       " 2021-06-11 01:59:30                      272.0                      253.0   \n",
       " \n",
       "                      cluster_2_temperature_237  cluster_2_temperature_238  \\\n",
       " MCGS_TIME                                                                   \n",
       " 2021-06-10 20:00:00                      275.0                      274.0   \n",
       " 2021-06-10 20:00:30                      275.0                      275.0   \n",
       " 2021-06-10 20:01:00                      276.0                      276.0   \n",
       " 2021-06-10 20:01:30                      276.0                      276.0   \n",
       " 2021-06-10 20:02:00                      277.0                      277.0   \n",
       " ...                                        ...                        ...   \n",
       " 2021-06-11 01:57:30                      232.0                      228.0   \n",
       " 2021-06-11 01:58:00                      232.0                      228.0   \n",
       " 2021-06-11 01:58:30                      232.0                      228.0   \n",
       " 2021-06-11 01:59:00                      232.0                      227.0   \n",
       " 2021-06-11 01:59:30                      231.0                      227.0   \n",
       " \n",
       "                      cluster_2_temperature_239  cluster_2_temperature_240  \\\n",
       " MCGS_TIME                                                                   \n",
       " 2021-06-10 20:00:00                      276.0                      274.0   \n",
       " 2021-06-10 20:00:30                      277.0                      275.0   \n",
       " 2021-06-10 20:01:00                      278.0                      276.0   \n",
       " 2021-06-10 20:01:30                      278.0                      276.0   \n",
       " 2021-06-10 20:02:00                      279.0                      277.0   \n",
       " ...                                        ...                        ...   \n",
       " 2021-06-11 01:57:30                      240.0                      258.0   \n",
       " 2021-06-11 01:58:00                      239.0                      257.0   \n",
       " 2021-06-11 01:58:30                      239.0                      257.0   \n",
       " 2021-06-11 01:59:00                      239.0                      257.0   \n",
       " 2021-06-11 01:59:30                      238.0                      256.0   \n",
       " \n",
       "                      cluster2_current  \n",
       " MCGS_TIME                              \n",
       " 2021-06-10 20:00:00      -1126.666667  \n",
       " 2021-06-10 20:00:30      -1127.833333  \n",
       " 2021-06-10 20:01:00      -1130.000000  \n",
       " 2021-06-10 20:01:30      -1128.833333  \n",
       " 2021-06-10 20:02:00      -1130.166667  \n",
       " ...                               ...  \n",
       " 2021-06-11 01:57:30          0.000000  \n",
       " 2021-06-11 01:58:00          0.000000  \n",
       " 2021-06-11 01:58:30          0.000000  \n",
       " 2021-06-11 01:59:00          0.000000  \n",
       " 2021-06-11 01:59:30          0.000000  \n",
       " \n",
       " [720 rows x 481 columns]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5abbf4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cluster_1_temperature_001',\n",
       " 'cluster_1_temperature_002',\n",
       " 'cluster_1_temperature_003',\n",
       " 'cluster_1_temperature_004',\n",
       " 'cluster_1_temperature_005',\n",
       " 'cluster_1_temperature_006',\n",
       " 'cluster_1_temperature_007',\n",
       " 'cluster_1_temperature_008',\n",
       " 'cluster_1_temperature_009',\n",
       " 'cluster_1_temperature_010',\n",
       " 'cluster_1_temperature_011',\n",
       " 'cluster_1_temperature_012',\n",
       " 'cluster_1_temperature_013',\n",
       " 'cluster_1_temperature_014',\n",
       " 'cluster_1_temperature_015',\n",
       " 'cluster_1_temperature_016',\n",
       " 'cluster_1_temperature_017',\n",
       " 'cluster_1_temperature_018',\n",
       " 'cluster_1_temperature_019',\n",
       " 'cluster_1_temperature_020',\n",
       " 'cluster_1_temperature_021',\n",
       " 'cluster_1_temperature_022',\n",
       " 'cluster_1_temperature_023',\n",
       " 'cluster_1_temperature_024',\n",
       " 'cluster_1_temperature_025',\n",
       " 'cluster_1_temperature_026',\n",
       " 'cluster_1_temperature_027',\n",
       " 'cluster_1_temperature_028',\n",
       " 'cluster_1_temperature_029',\n",
       " 'cluster_1_temperature_030',\n",
       " 'cluster_1_temperature_031',\n",
       " 'cluster_1_temperature_032',\n",
       " 'cluster_1_temperature_033',\n",
       " 'cluster_1_temperature_034',\n",
       " 'cluster_1_temperature_035',\n",
       " 'cluster_1_temperature_036',\n",
       " 'cluster_1_temperature_037',\n",
       " 'cluster_1_temperature_038',\n",
       " 'cluster_1_temperature_039',\n",
       " 'cluster_1_temperature_040',\n",
       " 'cluster_1_temperature_041',\n",
       " 'cluster_1_temperature_042',\n",
       " 'cluster_1_temperature_043',\n",
       " 'cluster_1_temperature_044',\n",
       " 'cluster_1_temperature_045',\n",
       " 'cluster_1_temperature_046',\n",
       " 'cluster_1_temperature_047',\n",
       " 'cluster_1_temperature_048',\n",
       " 'cluster_1_temperature_049',\n",
       " 'cluster_1_temperature_050',\n",
       " 'cluster_1_temperature_051',\n",
       " 'cluster_1_temperature_052',\n",
       " 'cluster_1_temperature_053',\n",
       " 'cluster_1_temperature_054',\n",
       " 'cluster_1_temperature_055',\n",
       " 'cluster_1_temperature_056',\n",
       " 'cluster_1_temperature_057',\n",
       " 'cluster_1_temperature_058',\n",
       " 'cluster_1_temperature_059',\n",
       " 'cluster_1_temperature_060',\n",
       " 'cluster_1_temperature_061',\n",
       " 'cluster_1_temperature_062',\n",
       " 'cluster_1_temperature_063',\n",
       " 'cluster_1_temperature_064',\n",
       " 'cluster_1_temperature_065',\n",
       " 'cluster_1_temperature_066',\n",
       " 'cluster_1_temperature_067',\n",
       " 'cluster_1_temperature_068',\n",
       " 'cluster_1_temperature_069',\n",
       " 'cluster_1_temperature_070',\n",
       " 'cluster_1_temperature_071',\n",
       " 'cluster_1_temperature_072',\n",
       " 'cluster_1_temperature_073',\n",
       " 'cluster_1_temperature_074',\n",
       " 'cluster_1_temperature_075',\n",
       " 'cluster_1_temperature_076',\n",
       " 'cluster_1_temperature_077',\n",
       " 'cluster_1_temperature_078',\n",
       " 'cluster_1_temperature_079',\n",
       " 'cluster_1_temperature_080',\n",
       " 'cluster_1_temperature_081',\n",
       " 'cluster_1_temperature_082',\n",
       " 'cluster_1_temperature_083',\n",
       " 'cluster_1_temperature_084',\n",
       " 'cluster_1_temperature_085',\n",
       " 'cluster_1_temperature_086',\n",
       " 'cluster_1_temperature_087',\n",
       " 'cluster_1_temperature_088',\n",
       " 'cluster_1_temperature_089',\n",
       " 'cluster_1_temperature_090',\n",
       " 'cluster_1_temperature_091',\n",
       " 'cluster_1_temperature_092',\n",
       " 'cluster_1_temperature_093',\n",
       " 'cluster_1_temperature_094',\n",
       " 'cluster_1_temperature_095',\n",
       " 'cluster_1_temperature_096',\n",
       " 'cluster_1_temperature_097',\n",
       " 'cluster_1_temperature_098',\n",
       " 'cluster_1_temperature_099',\n",
       " 'cluster_1_temperature_100',\n",
       " 'cluster_1_temperature_101',\n",
       " 'cluster_1_temperature_102',\n",
       " 'cluster_1_temperature_103',\n",
       " 'cluster_1_temperature_104',\n",
       " 'cluster_1_temperature_105',\n",
       " 'cluster_1_temperature_106',\n",
       " 'cluster_1_temperature_107',\n",
       " 'cluster_1_temperature_108',\n",
       " 'cluster_1_temperature_109',\n",
       " 'cluster_1_temperature_110',\n",
       " 'cluster_1_temperature_111',\n",
       " 'cluster_1_temperature_112',\n",
       " 'cluster_1_temperature_113',\n",
       " 'cluster_1_temperature_114',\n",
       " 'cluster_1_temperature_115',\n",
       " 'cluster_1_temperature_116',\n",
       " 'cluster_1_temperature_117',\n",
       " 'cluster_1_temperature_118',\n",
       " 'cluster_1_temperature_119',\n",
       " 'cluster_1_temperature_120',\n",
       " 'cluster_1_temperature_121',\n",
       " 'cluster_1_temperature_122',\n",
       " 'cluster_1_temperature_123',\n",
       " 'cluster_1_temperature_124',\n",
       " 'cluster_1_temperature_125',\n",
       " 'cluster_1_temperature_126',\n",
       " 'cluster_1_temperature_127',\n",
       " 'cluster_1_temperature_128',\n",
       " 'cluster_1_temperature_129',\n",
       " 'cluster_1_temperature_130',\n",
       " 'cluster_1_temperature_131',\n",
       " 'cluster_1_temperature_132',\n",
       " 'cluster_1_temperature_133',\n",
       " 'cluster_1_temperature_134',\n",
       " 'cluster_1_temperature_135',\n",
       " 'cluster_1_temperature_136',\n",
       " 'cluster_1_temperature_137',\n",
       " 'cluster_1_temperature_138',\n",
       " 'cluster_1_temperature_139',\n",
       " 'cluster_1_temperature_140',\n",
       " 'cluster_1_temperature_141',\n",
       " 'cluster_1_temperature_142',\n",
       " 'cluster_1_temperature_143',\n",
       " 'cluster_1_temperature_144',\n",
       " 'cluster_1_temperature_145',\n",
       " 'cluster_1_temperature_146',\n",
       " 'cluster_1_temperature_147',\n",
       " 'cluster_1_temperature_148',\n",
       " 'cluster_1_temperature_149',\n",
       " 'cluster_1_temperature_150',\n",
       " 'cluster_1_temperature_151',\n",
       " 'cluster_1_temperature_152',\n",
       " 'cluster_1_temperature_153',\n",
       " 'cluster_1_temperature_154',\n",
       " 'cluster_1_temperature_155',\n",
       " 'cluster_1_temperature_156',\n",
       " 'cluster_1_temperature_157',\n",
       " 'cluster_1_temperature_158',\n",
       " 'cluster_1_temperature_159',\n",
       " 'cluster_1_temperature_160',\n",
       " 'cluster_1_temperature_161',\n",
       " 'cluster_1_temperature_162',\n",
       " 'cluster_1_temperature_163',\n",
       " 'cluster_1_temperature_164',\n",
       " 'cluster_1_temperature_165',\n",
       " 'cluster_1_temperature_166',\n",
       " 'cluster_1_temperature_167',\n",
       " 'cluster_1_temperature_168',\n",
       " 'cluster_1_temperature_169',\n",
       " 'cluster_1_temperature_170',\n",
       " 'cluster_1_temperature_171',\n",
       " 'cluster_1_temperature_172',\n",
       " 'cluster_1_temperature_173',\n",
       " 'cluster_1_temperature_174',\n",
       " 'cluster_1_temperature_175',\n",
       " 'cluster_1_temperature_176',\n",
       " 'cluster_1_temperature_177',\n",
       " 'cluster_1_temperature_178',\n",
       " 'cluster_1_temperature_179',\n",
       " 'cluster_1_temperature_180',\n",
       " 'cluster_1_temperature_181',\n",
       " 'cluster_1_temperature_182',\n",
       " 'cluster_1_temperature_183',\n",
       " 'cluster_1_temperature_184',\n",
       " 'cluster_1_temperature_185',\n",
       " 'cluster_1_temperature_186',\n",
       " 'cluster_1_temperature_187',\n",
       " 'cluster_1_temperature_188',\n",
       " 'cluster_1_temperature_189',\n",
       " 'cluster_1_temperature_190',\n",
       " 'cluster_1_temperature_191',\n",
       " 'cluster_1_temperature_192',\n",
       " 'cluster_1_temperature_193',\n",
       " 'cluster_1_temperature_194',\n",
       " 'cluster_1_temperature_195',\n",
       " 'cluster_1_temperature_196',\n",
       " 'cluster_1_temperature_197',\n",
       " 'cluster_1_temperature_198',\n",
       " 'cluster_1_temperature_199',\n",
       " 'cluster_1_temperature_200',\n",
       " 'cluster_1_temperature_201',\n",
       " 'cluster_1_temperature_202',\n",
       " 'cluster_1_temperature_203',\n",
       " 'cluster_1_temperature_204',\n",
       " 'cluster_1_temperature_205',\n",
       " 'cluster_1_temperature_206',\n",
       " 'cluster_1_temperature_207',\n",
       " 'cluster_1_temperature_208',\n",
       " 'cluster_1_temperature_209',\n",
       " 'cluster_1_temperature_210',\n",
       " 'cluster_1_temperature_211',\n",
       " 'cluster_1_temperature_212',\n",
       " 'cluster_1_temperature_213',\n",
       " 'cluster_1_temperature_214',\n",
       " 'cluster_1_temperature_215',\n",
       " 'cluster_1_temperature_216',\n",
       " 'cluster_1_temperature_217',\n",
       " 'cluster_1_temperature_218',\n",
       " 'cluster_1_temperature_219',\n",
       " 'cluster_1_temperature_220',\n",
       " 'cluster_1_temperature_221',\n",
       " 'cluster_1_temperature_222',\n",
       " 'cluster_1_temperature_223',\n",
       " 'cluster_1_temperature_224',\n",
       " 'cluster_1_temperature_225',\n",
       " 'cluster_1_temperature_226',\n",
       " 'cluster_1_temperature_227',\n",
       " 'cluster_1_temperature_228',\n",
       " 'cluster_1_temperature_229',\n",
       " 'cluster_1_temperature_230',\n",
       " 'cluster_1_temperature_231',\n",
       " 'cluster_1_temperature_232',\n",
       " 'cluster_1_temperature_233',\n",
       " 'cluster_1_temperature_234',\n",
       " 'cluster_1_temperature_235',\n",
       " 'cluster_1_temperature_236',\n",
       " 'cluster_1_temperature_237',\n",
       " 'cluster_1_temperature_238',\n",
       " 'cluster_1_temperature_239',\n",
       " 'cluster_1_temperature_240']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_list[0]\n",
    "temperatrue_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d260896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg = re.compile(\"voltage\")\n",
    "\n",
    "\n",
    "# string = \"last\"\n",
    "# bool(re.match(reg, string))\"[a-zA-Z0-9_]+voltage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25431af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b25f7fd8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'voltage_paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bg/b5dfn0gj1lz88k7ms283yrlm0000gn/T/ipykernel_9815/1820757513.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_30sec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoltage_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'voltage_paths' is not defined"
     ]
    }
   ],
   "source": [
    "df_30sec = create_dataframe(voltage_paths[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4eef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "voltage_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7209d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_30sec.index == df_30sec_temperature.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92827ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_30sec\n",
    "df_30sec_temperature = create_dataframe(temperature_paths[0][0], \"temperature\")\n",
    "df_30sec_status = create_dataframe(state_paths[0][0], \"cluster1_current\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a34620f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719d05e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_30sec_temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119f69bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98919336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6624c76a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4236ce4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53926978",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = [pd.read_csv(path) for path in list_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8022fd63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26412607",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_30sec.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35f93c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_30sec = np.mean(df_30sec, axis = 1)\n",
    "adfuller(mean_30sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b7a18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_mean = mean_30sec.diff(periods=1).dropna()\n",
    "roll_mean.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8af2920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3283b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "adfuller(roll_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ea2b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.tsa.statespace.SARIMAX(mean_30sec, order = (3,1,2),  enforce_stationarity=False,\n",
    "                                            enforce_invertibility=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a347480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model and print results\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6543a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_30sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219cfa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = result.get_prediction(start = \"2021-06-10 17:30:00\", dynamic = False)\n",
    "pred_conf = pred.conf_int(alpha=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e08f2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot real vs predicted values along with confidence interval\n",
    "fig, axs = plt.subplots(figsize = (15, 6))\n",
    "\n",
    "# Plot observed values\n",
    "plt.plot(mean_30sec, label='observed')\n",
    "\n",
    "# Plot predicted values\n",
    "plt.plot(pred.predicted_mean, label = \"predicted\")\n",
    "\n",
    "# Plot the range for confidence intervals\n",
    "plt.fill_between(pred_conf.index, \n",
    "                 pred_conf.iloc[:,0],\n",
    "                 pred_conf.iloc[:,1], color = \"green\", alpha = 0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23c3e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot boundaries \n",
    "plt.plot(pred.predicted_mean - pred_conf.iloc[:,1], label = \"predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0f3b20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6ce034",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(df_30sec, axis = 1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8f6e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(df_30sec.loc['2021-06-10 18:40:00',:])*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc49e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_30sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5337be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_30sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6db909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7d8daa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b528d4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize = (15, 6))\n",
    "plt.plot(df_30sec)\n",
    "axs.set_title(\"Cell voltage idle/discharge/charge\")\n",
    "plt.vlines(x = df_30sec.index[180],ymin = 2800, ymax = 3400)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2c64c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check voltage sensor reading distribution during different moments of time.\n",
    "# idle\n",
    "print(f\"Voltage mean : {round(np.mean(df_30sec.loc['2021-06-10 18:00:00',:]/1000),2)} V\")\n",
    "print(f\"Voltage standard deviation : {round(np.std(df_30sec.loc['2021-06-10 18:00:00',:])/1000,4)} V\")\n",
    "df_30sec.loc['2021-06-10 18:00:00',:].hist(bins = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c87329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resting\n",
    "moment = '2021-06-10 19:00:00'\n",
    "print(f\"Voltage mean : {round(np.mean(df_30sec.loc[moment,:]/1000),2)} V\")\n",
    "print(f\"Voltage standard deviation : {round(np.std(df_30sec.loc[moment,:]/1000),4)} V\")\n",
    "df_30sec.loc[moment,:].hist(bins = 10)\n",
    "plt.title(\"Voltage distribution chart\")\n",
    "plt.xlabel(\"Voltage\")\n",
    "plt.ylabel(\"N of observations\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376eaa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charging\n",
    "print(f\"Voltage mean : {round(np.mean(df_30sec.loc['2021-06-10 19:30:00',:]/1000),2)} V\")\n",
    "print(f\"Voltage standard deviation : {round(np.std(df_30sec.loc['2021-06-10 19:30:00',:]/1000),4)} V\")\n",
    "df_30sec.loc['2021-06-10 19:30:00',:].hist(bins = 10)\n",
    "plt.title(\"Voltage distribution chart\")\n",
    "plt.xlabel(\"Voltage\")\n",
    "plt.ylabel(\"N of observations\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bc475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start of discharge\n",
    "print(f\"Voltage mean : {round(np.mean(df_30sec.loc['2021-06-10 18:35:00',:]/1000),2)} V\")\n",
    "print(f\"Voltage standard deviation : {round(np.std(df_30sec.loc['2021-06-10 19:00:00',:]/1000),4)} V\")\n",
    "df_30sec.loc['2021-06-10 19:00:00',:].hist(bins = 10)\n",
    "plt.title(\"Voltage distribution chart\")\n",
    "plt.xlabel(\"Voltage\")\n",
    "plt.ylabel(\"N of observations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0964ed87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Middle of discharge\n",
    "print(f\"Voltage mean : {round(np.mean(df_30sec.loc['2021-06-10 18:45:00',:]/1000),2)} V\")\n",
    "print(f\"Voltage standard deviation : {round(np.std(df_30sec.loc['2021-06-10 18:45:00',:]/1000),4)} V\")\n",
    "df_30sec.loc['2021-06-10 18:45:00',:].hist(bins = 10)\n",
    "plt.title(\"Voltage distribution chart\")\n",
    "plt.xlabel(\"Voltage\")\n",
    "plt.ylabel(\"N of observations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cd91dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets find end of discharge point\n",
    "timestamp_eod = [key for key, value in df_30sec.min(axis=1).items() if value == df_30sec.min(axis=1).min() ]\n",
    "timestamp_eod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5634968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of discharge\n",
    "print(f\"Voltage mean : {round(np.mean(df_30sec.loc['2021-06-10 18:53:00',:]/1000),2)} V\")\n",
    "print(f\"Voltage standard deviation : {round(np.std(df_30sec.loc['2021-06-10 18:53:00',:]/1000),4)} V\")\n",
    "df_30sec.loc['2021-06-10 18:53:00',:].hist(bins = 10)\n",
    "plt.title(\"Voltage distribution chart\")\n",
    "plt.xlabel(\"Voltage\")\n",
    "plt.ylabel(\"N of observations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3430bcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see voltage of cells is normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633181ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets draw changing of standard deviation of cells during the time\n",
    "fig, (top, bottom) = plt.subplots(2,1,figsize = (15, 10))\n",
    "top.plot(df_30sec)\n",
    "bottom.plot(np.std(df_30sec, axis = 1))\n",
    "top.set_title(\"Cell voltage during time\")\n",
    "top.set_ylabel(\"Voltage, mV\")\n",
    "top.set_xlabel(\"Time, seconds\")\n",
    "bottom.set_title(\"Cell voltage standard deviation\")\n",
    "bottom.set_ylabel(\"Voltage standard deviation, mV\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2687a9",
   "metadata": {},
   "source": [
    "As we can see, the most voltage difference batteries have at the end of discharge.\n",
    "\n",
    "This is the moment where cells tend to fail.\n",
    "\n",
    "##### We are focused on identifing anomalies when cell voltage exceed 3 standard deviations (probability 0.03% from Normal distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dcda2d",
   "metadata": {},
   "source": [
    "##### Check sensor precision based on manufacturer website\n",
    "http://www.bmser.com/?_l=en\n",
    "\n",
    "Based on information from website:\n",
    "\n",
    "\"24 Road monomer voltage acquisition (precision <5mV) \"\n",
    "##### We will use 5mV as a minimum threshold during idle time and maximum will be calculated for each point of time based on idea that we should mark sensors that have performance out of range - 3 standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29795de1",
   "metadata": {},
   "source": [
    "### Model preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587d7788",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_custom = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ade8ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Make new boundaries 2 and 3 std\n",
    "df_custom[\"mean\"] = np.mean(df_30sec, axis = 1)\n",
    "df_custom[\"lower_al\"] = df_custom[\"mean\"] - conf.low_voltage_alarm_n_std*np.std(df_30sec, axis = 1)\n",
    "df_custom[\"lower\"] = df_custom[\"mean\"] - conf.low_voltage_n_std*np.std(df_30sec, axis = 1)\n",
    "df_custom[\"upper_al\"] = df_custom[\"mean\"] + conf.high_voltage_n_std*np.std(df_30sec, axis = 1)\n",
    "df_custom[\"upper\"] = df_custom[\"mean\"] + conf.high_voltage_n_std*np.std(df_30sec, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77fb914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply sensors precision\n",
    "df_custom[\"upper\"][df_custom[\"upper\"] - df_custom[\"mean\"] < conf.sensor_v_prec] = df_custom[\"mean\"] + conf.sensor_v_prec\n",
    "df_custom[\"lower\"][df_custom[\"lower\"] - df_custom[\"mean\"] > -conf.sensor_v_prec] = df_custom[\"mean\"] - conf.sensor_v_prec\n",
    "df_custom[\"upper_al\"][df_custom[\"upper_al\"] - df_custom[\"mean\"] < conf.sensor_v_prec] = df_custom[\"mean\"] + conf.sensor_v_prec\n",
    "df_custom[\"lower_al\"][df_custom[\"lower_al\"] - df_custom[\"mean\"] > -conf.sensor_v_prec] = df_custom[\"mean\"] - conf.sensor_v_prec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3aa39f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fc4791",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "# Plot data predictions boundaries\n",
    "fig, axs = plt.subplots(figsize = (15, 6))\n",
    "\n",
    "# Plot observed values\n",
    "plt.plot(df_custom[\"mean\"], label='mean voltage', color = \"blue\", alpha = 0.6)\n",
    "\n",
    "plt.fill_between(df_custom.index, \n",
    "                 df_custom[\"lower\"],\n",
    "                 df_custom[\"upper\"], color = \"green\", alpha = 0.10, label = \"3 st deviation range\")\n",
    "\n",
    "# Plot the range for confidence intervals\n",
    "plt.fill_between(df_custom.index, \n",
    "                 df_custom[\"lower_al\"],\n",
    "                 df_custom[\"upper_al\"], color = \"green\", alpha = 0.15, label = \"2 st deviation range\")\n",
    "axs.set_title(\"Voltage vs time plot\")\n",
    "axs.set_xlabel(\"Time, Day/H/M\")\n",
    "axs.set_ylabel(\"Voltage, mV\")\n",
    "axs.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bc0f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_30sec[\"cluster_1_cellvoltage_240\"][(df_30sec[\"cluster_1_cellvoltage_240\"] < df_custom[\"lower\"]) & (result_list[0][\"cluster1_current\"] > 200)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8d0c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list[0][\"cluster1_current\"][\"2021-06-10 18:53:00\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ef5aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_30sec[\"cluster_1_cellvoltage_240\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1937486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# without status of system\n",
    "sensor_list = []\n",
    "for sensor in list(df_30sec.columns):\n",
    "    anomaly = df_30sec[sensor][(df_30sec[sensor] < df_custom[\"lower\"])] \n",
    "    if len(anomaly) > 0:\n",
    "        sensor_name = anomaly.name\n",
    "        sensor_list.append(sensor_name)\n",
    "print(sensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd45a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add status of system\n",
    "sensor_list = []\n",
    "for sensor in list(df_30sec.columns):\n",
    "    anomaly = df_30sec[sensor][(df_30sec[sensor] < df_custom[\"lower\"]) & (result_list[0][\"cluster1_current\"] >200)] \n",
    "    if len(anomaly) > 0:\n",
    "        sensor_name = anomaly.name\n",
    "        stage = \"discharge anomaly\"\n",
    "        sensor_list.append((anomaly, sensor_name, stage))\n",
    "print(sensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f45f5bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed0c320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e380f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore data distribution\n",
    "# Idle\n",
    "df_temperatures.loc[\"2021-06-10 17:40:00\",:].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4340b0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore data distribution\n",
    "# discharge\n",
    "df_temperatures.loc[\"2021-06-10 18:10:00\",:].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4ce1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore data distribution\n",
    "# idel\n",
    "df_temperatures.loc[\"2021-06-10 19:00:00\",:].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f1118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore data distribution\n",
    "# charge\n",
    "df_temperatures.loc[\"2021-06-10 19:30:00\",:].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24932e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can clearly see \"hot regions\" that probably formed due to cooled air distribution\n",
    "# Batteries recommended temperature should be within 10-40 degrees range. \n",
    "# Lets define "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9a8f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temperatures = result_list[0][temperatrue_columns]\n",
    "# Mean temperature\n",
    "df_temp = pd.DataFrame()\n",
    "df_temp[\"mean\"] = np.mean(df_temperatures, axis = 1)\n",
    "df_temp[\"lower_al\"] = df_temp[\"mean\"] - conf.low_temperature\n",
    "df_temp[\"lower\"] = df_temp[\"mean\"] - conf.low_temperature\n",
    "df_temp[\"upper_al\"] = df_temp[\"mean\"] + conf.high_temperature\n",
    "df_temp[\"upper\"] = df_temp[\"mean\"] + conf.high_temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba111bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_temperature = 100\n",
    "high_temperature = 100\n",
    "high_mean_temperature_alarm = 40\n",
    "Low_mean_temperature_alarm = 5\n",
    "\n",
    "\n",
    "# Plot data predictions boundaries\n",
    "fig, axs = plt.subplots(figsize = (15, 6))\n",
    "\n",
    "# Plot observed values\n",
    "plt.plot(df_temp[\"mean\"], label='mean voltage')\n",
    "\n",
    "plt.fill_between(df_temp.index, \n",
    "                 df_temp[\"lower\"],\n",
    "                 df_temp[\"upper\"], color = \"green\", alpha = 0.05)\n",
    "\n",
    "# Plot the range for confidence intervals\n",
    "plt.fill_between(df_temp.index, \n",
    "                 df_temp[\"lower_al\"],\n",
    "                 df_temp[\"upper_al\"], color = \"green\", alpha = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc77531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233825b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add status of system\n",
    "sensor_list = []\n",
    "for sensor in list(df_temperatures.columns):\n",
    "    anomaly = df_temperatures[sensor][(df_temp[\"mean\"] > conf.high_mean_temperature_alarm) | \n",
    "                                      (df_temp[\"mean\"] < conf.low_mean_temperature_alarm) |\n",
    "                                      (df_temperatures[sensor] < df_temp[\"lower\"]) | \n",
    "                                      (df_temperatures[sensor] > df_temp[\"upper\"])]\n",
    "    if len(anomaly) > 0:\n",
    "        sensor_name = anomaly.name\n",
    "        stage = \"temperature anomaly\"\n",
    "        sensor_list.append((anomaly, sensor_name, stage))\n",
    "print(sensor_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35ffcba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8357fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1508379",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list[0]\n",
    "temperatrue_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818ccdd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1662230",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for sensor in list(df_30sec.columns):\n",
    "    if df_30sec[sensor][df_30sec[sensor] < df_custom[\"lower\"]].sum() > 0:\n",
    "        print(sensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c122aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data predictions boundaries\n",
    "fig, axs = plt.subplots(figsize = (15, 10))\n",
    "\n",
    "# Plot observed values\n",
    "plt.plot(df_custom[\"mean\"], label='mean voltage')\n",
    "[plt.plot(df_30sec[sensor[1]]) for sensor in sensor_list]\n",
    "\n",
    "\n",
    "plt.fill_between(df_custom.index, \n",
    "                 df_custom[\"lower\"],\n",
    "                 df_custom[\"upper\"], color = \"green\", alpha = 0.1)\n",
    "\n",
    "# Plot the range for confidence intervals\n",
    "plt.fill_between(df_custom.index, \n",
    "                 df_custom[\"lower_al\"],\n",
    "                 df_custom[\"upper_al\"], color = \"green\", alpha = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc32883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987b9101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969f89f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3082bfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_30sec.loc[:,\"Cluster_1_CellVoltage_052\"] < df_custom[\"lower\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040ae793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4887f32e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e017528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7bb92f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5af8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eb48a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116e42b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df_30sec.loc['2021-06-10 18:42:00',:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5269e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(df_30sec.loc['2021-06-10 18:42:00',:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aff2784",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df_30sec.loc['2021-06-10 18:42:00',:]) - 2* np.std(df_30sec.loc['2021-06-10 18:42:00',:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d095c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32138135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4619324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot real vs predicted values along with confidence interval\n",
    "fig, axs = plt.subplots(figsize = (15, 6))\n",
    "\n",
    "# Plot observed values\n",
    "#plt.plot(mean_30sec, label='observed')\n",
    "\n",
    "# Plot predicted values\n",
    "plt.plot(mean_30sec, label = \"predicted\")\n",
    "\n",
    "# Plot the range for confidence intervals\n",
    "plt.fill_between(pred_conf.index, \n",
    "                 pred_conf.iloc[:,0],\n",
    "                 pred_conf.iloc[:,1], color = \"green\", alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565af231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c9bc60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d165a20c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7843bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape\n",
    "\n",
    "fig, axs = plt.subplots(1,1, figsize = (14,4))\n",
    "final_df.plot(ax = axs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6e5f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,1, figsize = (14,4))\n",
    "(np.mean(final_df, axis = 1) - final_df.min(axis = 1)).plot(ax = axs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50940ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make mean df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44889bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49455c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3238638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c4f8b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47bcc75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea97f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be13d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8a5288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2f0eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc95067",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,1, figsize = (24,8))\n",
    "np.mean(final_df, axis = 1).plot(ax = axs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fa4243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "model0 = ARIMA(np.mean(df2, axis = 1), dates=None,order=(2,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297540f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_arima = model0.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7679a8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xz = result_arima.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68c15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xz.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba7f697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace import SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3337068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6777d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3fa79e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c9dca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73837496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "model0 = ARIMA(np.mean(final_df, axis = 1), dates=None,order=(2,1,0))\n",
    "\n",
    "model1 = model0.fit(disp=1)\n",
    "\n",
    "decomposition = seasonal_decompose(np.array(np.mean(final_df, axis = 1)).reshape(len(np.mean(final_df, axis = 1)),),freq=1)\n",
    "### insert your data seasonality in 'freq'\n",
    "\n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal\n",
    "residual = decomposition.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c0330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eba682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcedc63e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e361342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full data tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27ddbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_folder2 = \"raw2/\"\n",
    "result_list2 = data_preprocess(raw_folder2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fee700",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a888f7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80da60aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_30sec = result_list2[0][voltage_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6759d314",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_custom = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a956bc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(df_30sec, axis = 1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0233ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_30sec[\"2021-06-10 11:28:30\"]\n",
    "\n",
    "# Make new boundaries 2 and 3 std\n",
    "df_custom[\"mean\"] = np.mean(df_30sec, axis = 1)\n",
    "df_custom[\"lower_al\"] = df_custom[\"mean\"] - conf.low_voltage_alarm_n_std*np.std(df_30sec[df_30sec > 2300], axis = 1)\n",
    "df_custom[\"lower\"] = df_custom[\"mean\"] - conf.low_voltage_n_std*np.std(df_30sec[df_30sec > 2300], axis = 1)\n",
    "df_custom[\"upper_al\"] = df_custom[\"mean\"] + conf.high_voltage_n_std*np.std(df_30sec[df_30sec > 2300], axis = 1)\n",
    "df_custom[\"upper\"] = df_custom[\"mean\"] + conf.high_voltage_n_std*np.std(df_30sec[df_30sec > 2300], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c13f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_custom.loc[\"2021-06-10 11:27:30\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d609e09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply sensors precision\n",
    "df_custom[\"upper\"][df_custom[\"upper\"] - df_custom[\"mean\"] < conf.sensor_v_prec] = df_custom[\"mean\"] + conf.sensor_v_prec\n",
    "df_custom[\"lower\"][df_custom[\"lower\"] - df_custom[\"mean\"] > -conf.sensor_v_prec] = df_custom[\"mean\"] - conf.sensor_v_prec\n",
    "df_custom[\"upper_al\"][df_custom[\"upper_al\"] - df_custom[\"mean\"] < conf.sensor_v_prec] = df_custom[\"mean\"] + conf.sensor_v_prec\n",
    "df_custom[\"lower_al\"][df_custom[\"lower_al\"] - df_custom[\"mean\"] > -conf.sensor_v_prec] = df_custom[\"mean\"] - conf.sensor_v_prec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ec0b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_custom[\"mean\"][\"2021-06-10 10:29:30\":\"2021-06-10 10:39:30\"]\n",
    "df_30sec.loc[\"2021-06-10 11:29:00\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd61d04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "(df_custom.index[-1] - df_custom.index[0]).days*24//12\n",
    "\n",
    "\n",
    "#df_custom.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa6e971",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "# Plot data predictions boundaries\n",
    "fig, axs = plt.subplots(figsize = (20, 8))\n",
    "\n",
    "# Plot observed values\n",
    "plt.plot(df_custom[\"mean\"], label='mean voltage', color = \"blue\", alpha = 0.6)\n",
    "\n",
    "plt.fill_between(df_custom.index, \n",
    "                 df_custom[\"lower\"],\n",
    "                 df_custom[\"upper\"], color = \"green\", alpha = 0.10, label = \"3 st deviation range\")\n",
    "\n",
    "# Plot the range for confidence intervals\n",
    "plt.fill_between(df_custom.index, \n",
    "                 df_custom[\"lower_al\"],\n",
    "                 df_custom[\"upper_al\"], color = \"green\", alpha = 0.15, label = \"2 st deviation range\")\n",
    "axs.set_title(\"Voltage vs time plot\")\n",
    "axs.set_xlabel(\"Time, Day/H/M\")\n",
    "axs.set_ylabel(\"Voltage, mV\")\n",
    "axs.legend()\n",
    "plt.xlim(df_custom.index[0], df_custom.index[0] + timedelta(hours = 12))\n",
    "plt.ylim(2700,3600)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e809617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_30sec[\"cluster_1_cellvoltage_240\"][(df_30sec[\"cluster_1_cellvoltage_240\"] < df_custom[\"lower\"]) & (result_list[0][\"cluster1_current\"] > 200)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85e4c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list[0][\"cluster1_current\"][\"2021-06-10 18:53:00\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161daa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_30sec[\"cluster_1_cellvoltage_240\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262f2f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# without status of system\n",
    "sensor_list = []\n",
    "for sensor in list(df_30sec.columns):\n",
    "    anomaly = df_30sec[sensor][(df_30sec[sensor] < df_custom[\"lower\"])] \n",
    "    if len(anomaly) > 0:\n",
    "        sensor_name = anomaly.name\n",
    "        sensor_list.append(sensor_name)\n",
    "print(sensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad0bd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make new boundaries 2 and 3 std\n",
    "# df_custom = pd.DataFrame()\n",
    "# df_custom[\"mean\"] = np.mean(df_30sec, axis = 1)\n",
    "# df_custom[\"lower_al\"] = df_custom[\"mean\"] - conf.low_voltage_alarm_n_std*np.std(df_30sec[df_30sec > 2300], axis = 1)\n",
    "# df_custom[\"lower\"] = df_custom[\"mean\"] - conf.low_voltage_n_std*np.std(df_30sec[df_30sec > 2300], axis = 1)\n",
    "# df_custom[\"upper_al\"] = df_custom[\"mean\"] + conf.high_voltage_n_std*np.std(df_30sec[df_30sec > 2300], axis = 1)\n",
    "# df_custom[\"upper\"] = df_custom[\"mean\"] + conf.high_voltage_n_std*np.std(df_30sec[df_30sec > 2300], axis = 1)\n",
    "# # Apply sensors precision\n",
    "# df_custom[\"upper\"][df_custom[\"upper\"] - df_custom[\"mean\"] < conf.sensor_v_prec] = df_custom[\"mean\"] + conf.sensor_v_prec\n",
    "# df_custom[\"lower\"][df_custom[\"lower\"] - df_custom[\"mean\"] > -conf.sensor_v_prec] = df_custom[\"mean\"] - conf.sensor_v_prec\n",
    "# df_custom[\"upper_al\"][df_custom[\"upper_al\"] - df_custom[\"mean\"] < conf.sensor_v_prec] = df_custom[\"mean\"] + conf.sensor_v_prec\n",
    "# df_custom[\"lower_al\"][df_custom[\"lower_al\"] - df_custom[\"mean\"] > -conf.sensor_v_prec] = df_custom[\"mean\"] - conf.sensor_v_prec\n",
    "\n",
    "\n",
    "\n",
    "def create_thresholds()\n",
    "\n",
    "\n",
    "\n",
    "def find_anomaly_voltage(dataframe, thresholds):\n",
    "    \n",
    "    sensor_list = []\n",
    "    for sensor in list(dataframe.columns):\n",
    "        anomaly = dataframe[sensor][(dataframe[sensor] < thresholds[\"lower\"]) & (!!result_list[0][\"cluster1_current\"] >200)] \n",
    "    if len(anomaly) > 0:\n",
    "        sensor_name = anomaly.name\n",
    "        stage = \"discharge anomaly\"\n",
    "        sensor_list.append((anomaly, sensor_name, stage))\n",
    "    print(sensor_list)\n",
    "    return sensor_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea2e360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add status of system\n",
    "sensor_list = []\n",
    "for sensor in list(df_30sec.columns):\n",
    "    anomaly = df_30sec[sensor][(df_30sec[sensor] < df_custom[\"lower\"]) & (result_list[0][\"cluster1_current\"] >200)] \n",
    "    if len(anomaly) > 0:\n",
    "        sensor_name = anomaly.name\n",
    "        stage = \"discharge anomaly\"\n",
    "        sensor_list.append((anomaly, sensor_name, stage))\n",
    "print(sensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619a1eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data predictions boundaries\n",
    "fig, axs = plt.subplots(figsize = (20, 8))\n",
    "\n",
    "\n",
    "# Plot observed values\n",
    "plt.plot(df_custom[\"mean\"], label='mean voltage', c = \"black\")\n",
    "[plt.plot(df_30sec[sensor[1]], label = sensor[1], color = cmap(number)) for number, sensor in enumerate(sensor_list)]\n",
    "[plt.plot(sensor[0], label = \"alarm \" + sensor[1], c = \"red\", marker = markers[number],markersize = 8, linestyle=\"\") for number, sensor in enumerate(sensor_list)]\n",
    "\n",
    "plt.fill_between(df_custom.index, \n",
    "                 df_custom[\"lower\"],\n",
    "                 df_custom[\"upper\"], color = \"green\", alpha = 0.1, label = \"3 st deviation range\")\n",
    "\n",
    "# Plot the range for confidence intervals\n",
    "plt.fill_between(df_custom.index, \n",
    "                 df_custom[\"lower_al\"],\n",
    "                 df_custom[\"upper_al\"], color = \"green\", alpha = 0.15)\n",
    "\n",
    "date_form = DateFormatter(\"%b%d-%H:%M:%S\")\n",
    "axs.xaxis.set_major_formatter(date_form)\n",
    "plt.ylim(2700,3600)\n",
    "#plt.xlim(df_custom.index[0], df_custom.index[0] + timedelta(hours = 12))\n",
    "axs.set_title(\"Voltage vs time plot\")\n",
    "axs.set_xlabel(\"Time, Day/H/M\")\n",
    "axs.set_ylabel(\"Voltage, mV\")\n",
    "\n",
    "plt.legend()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bcd29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap(4)\n",
    "plt.get_cmap(cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e2b32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517c6e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ed4a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2dd5b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c0500c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee881a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a04b3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41690fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f766909e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bd221f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b80557a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0952f70a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581ff3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca44a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c8c165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f4d4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_dir = 'train/'\n",
    "data_train_clean = 'train_cleaned/'\n",
    "new_dir = 'data/'\n",
    "test_dir = \"test/\"\n",
    "data_test_after = \"after/\"\n",
    "raw_folder = \"raw/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce56cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path\n",
    "train = os.path.join(new_dir, data_train_dir)\n",
    "train_clean = os.path.join(new_dir, data_train_clean)\n",
    "\n",
    "test_folder = os.path.join(new_dir, test_dir)\n",
    "test_folder_after = os.path.join(test_folder, data_test_after)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9905b6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613d39a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories\n",
    "os.mkdir(new_dir)\n",
    "os.mkdir(test_folder)\n",
    "\n",
    "os.mkdir(train)\n",
    "os.mkdir(train_clean)\n",
    "\n",
    "os.mkdir(test_folder_after)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dfdead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack data\n",
    "with zipfile.ZipFile(raw_folder + 'train.zip', 'r') as zip_train:\n",
    "    zip_train.extractall(new_dir)\n",
    "with zipfile.ZipFile(raw_folder + 'train_cleaned.zip', 'r') as zip_train_clean:\n",
    "    zip_train_clean.extractall(new_dir)\n",
    "with zipfile.ZipFile(raw_folder + 'test.zip', 'r') as zip_test:\n",
    "    zip_test.extractall(new_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05079c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train set\n",
    "imgs_train = sorted([file for file in os.listdir(train) if file.endswith('.png')])\n",
    "imgs_train_clean = sorted([file for file in os.listdir(train_clean) if file.endswith('.png')])\n",
    "\n",
    "# Test set\n",
    "imgs_test = sorted([file for file in os.listdir(test_folder) if file.endswith('.png')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aab53db",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc100668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b31b99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train set:\")\n",
    "print('There are', len(imgs_train), 'normal images, image name example,',os.listdir(train)[0])\n",
    "print('There are', len(imgs_train_clean), 'pneumonia images, image name example,',os.listdir(train_clean)[0])\n",
    "print(\"Test set:\")\n",
    "print('There are', len(imgs_test), 'normal images, image name example,',os.listdir(test_folder)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f1f5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_number = len(imgs_train)\n",
    "val_img_number = len(imgs_train_clean)\n",
    "test_img_number = len(imgs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da318c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data without aug\n",
    "def process_data_no_aug(img_size):\n",
    "    # Data generation objects\n",
    "    # get all the data in the directory split/train, and reshape them\n",
    "    train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train, \n",
    "        target_size=img_size, batch_size= train_img_number)\n",
    "\n",
    "    # get all the data in the directory split/validation, and reshape them\n",
    "    val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_clean, \n",
    "        target_size=img_size, batch_size = val_img_number)\n",
    "\n",
    "    # get all the data in the directory split/test, and reshape them\n",
    "    test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_folder, \n",
    "        target_size=img_size, batch_size = test_img_number) \n",
    "\n",
    "    \n",
    "    \n",
    "    return train_generator, val_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41f40d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d68c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (540,420)\n",
    "train_generator, val_generator, test_generator = process_data_no_aug(image_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072514a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 8 random photos of normal and pneumonia X-ray\n",
    "fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(20,20))\n",
    "\n",
    "for x in range(0,4):\n",
    "        i = np.random.randint(0,len(imgs_train))\n",
    "        axes[x][0].imshow(imgs_train[i])\n",
    "        axes[x][1].imshow(imgs_train_clean[i])\n",
    "\n",
    "#         if train_labels[i][0] == 0:\n",
    "#             axes[x][y].set_title('Normal')\n",
    "#         else:\n",
    "#             axes[x][y].set_title('Pneumonia')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e267b8b1",
   "metadata": {},
   "source": [
    "Make new split directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802f7c7f",
   "metadata": {},
   "source": [
    "### Setting up help functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03922d12",
   "metadata": {},
   "source": [
    "##### Results visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e34177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots of losses.\n",
    "def visualize_training_results(results):\n",
    "    # Create figures\n",
    "    fig, (left, right) = plt.subplots(1,2, figsize = (16,6))\n",
    "    history = results.history\n",
    "    # Loss functions plot\n",
    "    left.plot(history['val_loss'], label = \"val loss\")\n",
    "    left.plot(history['loss'], label = \"loss\")\n",
    "    left.set_title('Loss')\n",
    "    left.set_xlabel('Epochs')\n",
    "    left.set_ylabel('Loss')\n",
    "    left.legend()\n",
    "    # Accuracy plot\n",
    "    right.plot(history['val_accuracy'], label = \"val accuracy\")\n",
    "    right.plot(history['accuracy'], label = \"accuracy\")\n",
    "    right.set_title('Accuracy')\n",
    "    right.set_xlabel('Epochs')\n",
    "    right.set_ylabel('Accuracy')\n",
    "    right.legend()\n",
    "    path = \"./img/Loss_\"+model_name+\".png\"\n",
    "    plt.savefig(path)\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7782eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data with aug\n",
    "def process_data_aug(img_size, batch_size):\n",
    "    # Data generation objects\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                       rotation_range=20,   \n",
    "                                       zoom_range=0.2,\n",
    "                                       width_shift_range=0.2, \n",
    "                                       height_shift_range=0.2,\n",
    "                                       vertical_flip=True)\n",
    "    test_val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    # This is fed to the network in the specified batch sizes and image dimensions\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "      directory=train_folder, \n",
    "      target_size=img_size, \n",
    "      batch_size=92, \n",
    "      class_mode='binary',\n",
    "      shuffle = True)\n",
    "\n",
    "    val_generator = test_val_datagen.flow_from_directory(\n",
    "      directory=val_folder, \n",
    "      target_size=img_size, \n",
    "      batch_size=32, \n",
    "      class_mode='binary',\n",
    "      shuffle = True)\n",
    "    \n",
    "    test_generator = test_val_datagen.flow_from_directory(\n",
    "        test_folder, \n",
    "        target_size=img_size, \n",
    "        batch_size = test_img_number)  \n",
    "    \n",
    "    \n",
    "    return train_generator, val_generator, test_generator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155cac12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data without aug\n",
    "def process_data_no_aug(img_size):\n",
    "    # Data generation objects\n",
    "    # get all the data in the directory split/train, and reshape them\n",
    "    train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_folder, \n",
    "        target_size=img_size, batch_size= train_img_number)\n",
    "\n",
    "    # get all the data in the directory split/validation, and reshape them\n",
    "    val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_folder, \n",
    "        target_size=img_size, batch_size = val_img_number)\n",
    "\n",
    "    # get all the data in the directory split/test, and reshape them\n",
    "    test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_folder, \n",
    "        target_size=img_size, batch_size = test_img_number) \n",
    "\n",
    "    \n",
    "    \n",
    "    return train_generator, val_generator, test_generator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fdf34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \n",
    "    plt.figure(figsize = (6,6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    cm = np.round(cm,2)\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    path = \"./img/CM_\"+model_name+\".png\"\n",
    "    plt.savefig(path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0449a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results:\n",
    "# - Loss, accuracy for val and train sets during training. \n",
    "# - Confusion matrix for test results. \n",
    "\n",
    "def plot_results(results, model, test_images,  test_y =None, threshold = 0.5,):\n",
    "    visualize_training_results(results)\n",
    "    predictions = model.predict(test_images)\n",
    "    predictions = [1 if x > threshold else 0 for x in predictions]\n",
    "    accuracy = accuracy_score(test_y, predictions)\n",
    "    recall = recall_score(test_y, predictions)\n",
    "    print('Test Accuracy = %.2f' % accuracy)# Combined plotting. \n",
    "\n",
    "    print('Recall = %.2f' % recall)\n",
    "    confusion_mtx = confusion_matrix(test_y, predictions)\n",
    "    cm = plot_confusion_matrix(confusion_mtx, classes = [\"normal\", \"pneumonia\"], normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafb52db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with finall results.\n",
    "result_columns = [\"Model name\",\"Image size\",\"Parameters\",\"Train time\",\"Train accuracy\", \"Validation accuracy\", \"Test accuracy\", \"Test Recall\"]\n",
    "results_df = pd.DataFrame(columns = result_columns)\n",
    "\n",
    "                  \n",
    "# Results:\n",
    "def make_results(model_selection, image_size, train_time,model_name, results, model, test_images, test_y, threshold = 0.5):\n",
    "    predictions = model.predict(test_images)\n",
    "    predictions = [1 if x > threshold else 0 for x in predictions]\n",
    "    test_accuracy = round(accuracy_score(test_y, predictions),4)\n",
    "    test_recall = round(recall_score(test_y, predictions),4)\n",
    "    train_accuracy = round(results.history[\"accuracy\"][-1],4)\n",
    "    val_accuracy = round(results.history[\"val_accuracy\"][-1],4)\n",
    "    train_epoch = len(results.epoch)\n",
    "    N_of_params = int(np.sum([np.prod(v.get_shape().as_list()) for v in model.trainable_variables]) + np.sum([np.prod(v.get_shape().as_list()) for v in model.non_trainable_variables]))\n",
    "    line = pd.DataFrame(np.array([[model_name, image_size, N_of_params,\n",
    "                               train_time, train_accuracy, val_accuracy,\n",
    "                               test_accuracy, test_recall]]), columns = result_columns)\n",
    "    model_selection = pd.concat([model_selection,line], axis = 0)\n",
    "    return model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3b4516",
   "metadata": {},
   "source": [
    "### Use a densely connected network as a baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9c4683",
   "metadata": {},
   "source": [
    "##### Prepare images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a4f42d",
   "metadata": {},
   "source": [
    "##### 64x64 images without data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966152ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (64,64)\n",
    "train_generator, val_generator, test_generator = process_data_no_aug(image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9eb2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare images and lables.\n",
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)\n",
    "val_images, val_labels = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062df8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore dataset\n",
    "m_train = train_images.shape[0]\n",
    "num_px = train_images.shape[1]\n",
    "m_test = test_images.shape[0]\n",
    "m_val = val_images.shape[0]\n",
    "\n",
    "print (\"Number of training samples: \" + str(m_train))\n",
    "print (\"Number of testing samples: \" + str(m_test))\n",
    "print (\"Number of validation samples: \" + str(m_val))\n",
    "print (\"train_images shape: \" + str(train_images.shape))\n",
    "print (\"train_labels shape: \" + str(train_labels.shape))\n",
    "print (\"test_images shape: \" + str(test_images.shape))\n",
    "print (\"test_labels shape: \" + str(test_labels.shape))\n",
    "print (\"val_images shape: \" + str(val_images.shape))\n",
    "print (\"val_labels shape: \" + str(val_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da3c8d2",
   "metadata": {},
   "source": [
    "##### Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fef3f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 16 random photos of normal and pneumonia X-ray\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(20,20))\n",
    "\n",
    "for x in range(0,4):\n",
    "    for y in range(0, 4):\n",
    "        i = np.random.randint(0,len(train_images))\n",
    "        axes[x][y].imshow(train_images[i])\n",
    "        \n",
    "        if train_labels[i][0] == 0:\n",
    "            axes[x][y].set_title('Normal')\n",
    "        else:\n",
    "            axes[x][y].set_title('Pneumonia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39b846a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finall features set:\n",
    "train_img = train_images.reshape(train_images.shape[0], -1)\n",
    "test_img = test_images.reshape(test_images.shape[0], -1)\n",
    "val_img = val_images.reshape(val_images.shape[0], -1)\n",
    "\n",
    "print(train_img.shape)\n",
    "print(test_img.shape)\n",
    "print(val_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1703fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels. \n",
    "train_y = np.reshape(train_labels[:,0], (train_img_number,1))\n",
    "test_y = np.reshape(test_labels[:,0], (test_img_number,1))\n",
    "val_y = np.reshape(val_labels[:,0], (val_img_number,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0045b9fc",
   "metadata": {},
   "source": [
    "##### 1) Prepare 1st Baseline mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeeff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize 1st mode.\n",
    "\n",
    "np.random.seed(123)\n",
    "model_name = \"Baseline_model\"\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(50, activation='relu', input_shape=(train_img.shape[1],))) # 2 hidden layers\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efbc3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "history_base = model.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(val_img, val_y))\n",
    "end = time.time()\n",
    "train_time = round(end-start, 0)\n",
    "savepath = \"./data/models/\"+model_name+\".h5\"\n",
    "model.save(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb668e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process results\n",
    "\n",
    "results_df = make_results(results_df,image_size,train_time,model_name,history_base, model, test_img, test_y)\n",
    "display(results_df)\n",
    "plot_results(history_base, model, test_img,  test_y,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41057bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ec3f54a",
   "metadata": {},
   "source": [
    "##### 2) Baseline model with regulization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfaf58e",
   "metadata": {},
   "source": [
    "We will use L2 regulization in each layer, to reduce overfitting.\n",
    "Will try different L2 coefficients to determine the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b232820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets find the best L2 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346d496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_list = [0.001, 0.01, 0.1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c137677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_fin = []\n",
    "for L2 in L2_list:\n",
    "    model2 = models.Sequential()\n",
    "    model2.add(layers.Dense(50, activation='relu', input_shape=(train_img.shape[1],), kernel_regularizer = l2(l2 = L2))) \n",
    "    model2.add(layers.Dense(10, activation='relu', kernel_regularizer = l2(l2 = L2)))\n",
    "    model2.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model2.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    history_model2 = model2.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(val_img, val_y),\n",
    "                    verbose = 0)\n",
    "    results_test = model2.evaluate(test_img, test_y)\n",
    "    L2_fin.append((L2, results_test[1]))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a387a9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_best = sorted(L2_fin, key = lambda x: x[1], reverse = True)[0][0]\n",
    "print(\"Best L2 regulization parameter:\", L2_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbd4960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with regulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4862c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Baseline with reg\"\n",
    "model2 = models.Sequential()\n",
    "model2.add(layers.Dense(50, activation='relu', input_shape=(train_img.shape[1],), kernel_regularizer = l2(l2 = L2_best)))\n",
    "model2.add(layers.Dense(25, activation='relu', kernel_regularizer = l2(l2 = L2_best)))\n",
    "model2.add(layers.Dense(10, activation='relu', kernel_regularizer = l2(l2 = L2_best)))\n",
    "model2.add(layers.Dense(1, activation='sigmoid'))\n",
    "model2.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "history_model2 = model2.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(val_img, val_y),\n",
    "                    verbose = 1)\n",
    "end = time.time()\n",
    "train_time = round(end-start, 0)\n",
    "savepath = \"./data/models/\"+model_name+\".h5\"\n",
    "model2.save(savepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d00789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = make_results(results_df,image_size,train_time,model_name,history_model2, model2, test_img, test_y)\n",
    "display(results_df)\n",
    "plot_results(history_model2, model2, test_img, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5a503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ead1c0c",
   "metadata": {},
   "source": [
    "##### 3) Baseline model with regulization and Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2123e09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Baseline with reg, dropout\"\n",
    "model3 = models.Sequential()\n",
    "model3.add(layers.Dense(50, activation='relu', input_shape=(train_img.shape[1],), kernel_regularizer = l2(l2 = L2_best)))\n",
    "model3.add(layers.Dropout(0.5))\n",
    "model3.add(layers.Dense(25, activation='relu', kernel_regularizer = l2(l2 = 0.01)))\n",
    "model3.add(layers.Dropout(0.5))\n",
    "model3.add(layers.Dense(10, activation='relu', kernel_regularizer = l2(l2 = 0.01)))\n",
    "model3.add(layers.Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc12934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "start = time.time()\n",
    "history_model3 = model3.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(val_img, val_y))\n",
    "end = time.time()\n",
    "train_time = round(end-start, 0)\n",
    "savepath = \"./data/models/\"+model_name+\".h5\"\n",
    "model3.save(savepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a729d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = make_results(results_df,image_size,train_time,model_name,history_model3, model3, test_img, test_y)\n",
    "display(results_df)\n",
    "plot_results(history_model3, model3, test_img, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb04fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b7be60",
   "metadata": {},
   "source": [
    "##### 4) Baseline model with regulization and Dropout. Changed  optimizer to Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2378ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Baseline with reg, dropout, optimizer\"\n",
    "\n",
    "model4 = models.Sequential()\n",
    "model4.add(layers.Dense(50, activation='relu', input_shape=(train_img.shape[1],), kernel_regularizer = l2(l2 = L2_best)))\n",
    "model4.add(layers.Dropout(0.5))\n",
    "model4.add(layers.Dense(25, activation='relu', kernel_regularizer = l2(l2 = 0.01)))\n",
    "model4.add(layers.Dropout(0.5))\n",
    "model4.add(layers.Dense(10, activation='relu', kernel_regularizer = l2(l2 = L2_best)))\n",
    "model4.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e37b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "start = time.time()\n",
    "history_model4 = model4.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(val_img, val_y))\n",
    "end = time.time()\n",
    "train_time = round(end-start, 0)\n",
    "savepath = \"./data/models/\"+model_name+\".h5\"\n",
    "model4.save(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477553b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train4 = model4.evaluate(train_img, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe35904",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = make_results(results_df,image_size,train_time,model_name,history_model4, model4, test_img, test_y)\n",
    "display(results_df)\n",
    "plot_results(history_model4, model4, test_img, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee33d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test4 = model4.evaluate(test_img, test_y)\n",
    "print(f\"Test set results accuracy {results_test4[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fa9f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model has serious overfitting issues. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f1b81b",
   "metadata": {},
   "source": [
    "##### 5) Baseline + regulization + Dropout + Adam optimizer + increased train time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88299e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Baseline with reg, dropout, optimizer + extra train time\"\n",
    "\n",
    "model5 = models.Sequential()\n",
    "model5.add(layers.Dense(50, activation='relu', input_shape=(train_img.shape[1],), kernel_regularizer = l2(l2 = 0.01)))\n",
    "model5.add(layers.Dropout(0.5))\n",
    "model5.add(layers.Dense(25, activation='relu', kernel_regularizer = l2(l2 = 0.01)))\n",
    "model5.add(layers.Dropout(0.5))\n",
    "model5.add(layers.Dense(10, activation='relu', kernel_regularizer = l2(l2 = 0.01)))\n",
    "model5.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b8383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "start = time.time()\n",
    "history_model5 = model5.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=50,\n",
    "                    batch_size=50,\n",
    "                    validation_data=(val_img, val_y))\n",
    "end = time.time()\n",
    "train_time = round(end-start, 0)\n",
    "savepath = \"./data/models/\"+model_name+\".h5\"\n",
    "model5.save(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e00cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = make_results(results_df,image_size,train_time,model_name,history_model5, model5, test_img, test_y)\n",
    "display(results_df)\n",
    "plot_results(history_model5, model5, test_img, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30b5b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test5 = model5.evaluate(test_img, test_y)\n",
    "print(f\"Test set results accuracy {results_test5[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb6c5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model has serious overfitting issues. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16625a37",
   "metadata": {},
   "source": [
    "##### 6) Basic CNN model, image shape 64x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7ef567",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Basic CNN\"\n",
    "\n",
    "model_CNN = models.Sequential()\n",
    "model_CNN.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(64 ,64, 3)))\n",
    "model_CNN.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_CNN.add(layers.Conv2D(64, (4, 4), activation='relu'))\n",
    "model_CNN.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_CNN.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_CNN.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_CNN.add(layers.Flatten())\n",
    "model_CNN.add(layers.Dense(16, activation='relu'))\n",
    "model_CNN.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_CNN.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df83dfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "history_CNN1 = model_CNN.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=15,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(val_images, val_y))\n",
    "end = time.time()\n",
    "train_time = round(end-start, 0)\n",
    "savepath = \"./data/models/\"+model_name+\".h5\"\n",
    "model_CNN.save(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d586db52",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test = model_CNN.evaluate(test_images, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9407d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = make_results(results_df,image_size,train_time,model_name,history_CNN1, model_CNN, test_images, test_y)\n",
    "display(results_df)\n",
    "plot_results(history_CNN1, model_CNN, test_images, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772394db",
   "metadata": {},
   "source": [
    "##### 7) Basic CNN, shape 64 x 64 with regulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee385c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Basic CNN with reg, dropout\"\n",
    "\n",
    "model_CNN2 = models.Sequential()\n",
    "model_CNN2.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(64 ,64, 3)))\n",
    "model_CNN2.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_CNN2.add(layers.Conv2D(32, (4, 4), activation='relu'))\n",
    "model_CNN2.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_CNN2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_CNN2.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_CNN2.add(layers.Flatten())\n",
    "model_CNN2.add(layers.Dense(16, activation='relu', kernel_regularizer = l2(l2 = L2_best)))\n",
    "model_CNN2.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_CNN2.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"Adam\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c709fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efe0651",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "history_CNN2 = model_CNN2.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=15,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(val_images, val_y))\n",
    "end = time.time()\n",
    "train_time = round(end-start, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f53035",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test = model_CNN2.evaluate(test_images, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02a842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = make_results(results_df,image_size,train_time,model_name,history_CNN2, model_CNN2, test_images, test_y)\n",
    "display(results_df)\n",
    "plot_results(history_CNN2, model_CNN2, test_images, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32a4bfd",
   "metadata": {},
   "source": [
    "##### 7) Basic CNN, shape 100 x 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741d9d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reshape images to 100x100\n",
    "\n",
    "image_size = (100,100)\n",
    "train_generator_100, val_generator_100, test_generator_100 = process_data_no_aug(image_size)\n",
    "\n",
    "train_images2, train_labels2 = next(train_generator_100)\n",
    "test_images2, test_labels2 = next(test_generator_100)\n",
    "val_images2, val_labels2 = next(val_generator_100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85439569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape images\n",
    "train_img2 = train_images2.reshape(train_images2.shape[0], -1)\n",
    "test_img2 = test_images2.reshape(test_images2.shape[0], -1)\n",
    "val_img2 = val_images2.reshape(val_images2.shape[0], -1)\n",
    "\n",
    "# Check the shape after. \n",
    "print(train_img2.shape)\n",
    "print(test_img2.shape)\n",
    "print(val_img2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e8723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "train_y2 = np.reshape(train_labels[:,0], (train_img_number,1))\n",
    "test_y2 = np.reshape(test_labels[:,0], (test_img_number,1))\n",
    "val_y2 = np.reshape(val_labels[:,0], (val_img_number,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5756ca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model.\n",
    "model_name = \"Basic CNN 100x100\"\n",
    "\n",
    "model_CNN3 = models.Sequential()\n",
    "model_CNN3.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(100 ,100, 3)))\n",
    "model_CNN3.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_CNN3.add(layers.Conv2D(32, (4, 4), activation='relu'))\n",
    "model_CNN3.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_CNN3.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_CNN3.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_CNN3.add(layers.Flatten())\n",
    "model_CNN3.add(layers.Dense(16, activation='relu'))\n",
    "model_CNN3.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_CNN3.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47e5b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "history_CNN3 = model_CNN3.fit(train_images2,\n",
    "                    train_y2,\n",
    "                    epochs=10,\n",
    "                    batch_size=50,\n",
    "                    validation_data=(val_images2, val_y2))\n",
    "end = time.time()\n",
    "train_time = round(end-start, 0)\n",
    "savepath = \"./data/models/\"+model_name+\".h5\"\n",
    "model_CNN3.save(savepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138e51ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test = model_CNN3.evaluate(test_images2, test_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a31d1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = make_results(results_df,image_size,train_time,model_name,history_CNN3, model_CNN3, test_images2, test_y2)\n",
    "display(results_df)\n",
    "plot_results(history_CNN3, model_CNN3, test_images2, test_y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ef62d8",
   "metadata": {},
   "source": [
    "##### 8) Basic CNN, shape 100 x 100 with regulization and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c11e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Basic CNN 100x100 with reg and dropout\"\n",
    "\n",
    "model_CNN4 = models.Sequential()\n",
    "model_CNN4.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(100 ,100, 3)))\n",
    "model_CNN4.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_CNN4.add(layers.Conv2D(64, (4, 4), activation='relu'))\n",
    "model_CNN4.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_CNN4.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_CNN4.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_CNN4.add(layers.Flatten())\n",
    "model_CNN4.add(layers.Dense(16, activation='relu', kernel_regularizer = l2(l2 = 0.01)))\n",
    "model_CNN4.add(layers.Dropout(0.3))\n",
    "model_CNN4.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_CNN4.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d2d2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "history_CNN4 = model_CNN4.fit(train_images2,\n",
    "                    train_y2,\n",
    "                    epochs=15,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(val_images2, val_y2))\n",
    "end = time.time()\n",
    "train_time = round(end-start, 0)\n",
    "savepath = \"./data/models/\"+model_name+\".h5\"\n",
    "model_CNN4.save(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55537c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test = model_CNN4.evaluate(test_images2, test_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265c99c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = make_results(results_df,image_size,train_time,model_name,history_CNN4, model_CNN4, test_images2, test_y2)\n",
    "display(results_df)\n",
    "plot_results(history_CNN4, model_CNN4, test_images2, test_y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70153f22",
   "metadata": {},
   "source": [
    "##### Change data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4e565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (100,100)\n",
    "batch_size = 120\n",
    "train_generator_arg_100, val_generator_arg_100, test_generator_arg_100 = process_data_aug(image_size, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3da3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_100_arg, train_labels_100_arg = next(train_generator_arg_100)\n",
    "test_images_100_arg, test_labels_100_arg = next(test_generator_arg_100)\n",
    "val_images_100_arg, val_labels_100_arg = next(val_generator_arg_100)\n",
    "\n",
    "#test_y = np.reshape(test_labels_100_arg[:,], (test_img_number,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fc46f1",
   "metadata": {},
   "source": [
    "##### 9) Augment CNN, shape 100 x 100 with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0efe6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Augmented CNN 100x100 with reg\"\n",
    "\n",
    "model_CNN6 = models.Sequential()\n",
    "model_CNN6.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(100 ,100, 3)))\n",
    "model_CNN6.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_CNN6.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_CNN6.add(layers.MaxPooling2D((2, 2)))\n",
    "model_CNN6.add(layers.Dropout(0.2))\n",
    "\n",
    "model_CNN6.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_CNN6.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_CNN6.add(layers.Flatten())\n",
    "model_CNN6.add(layers.Dense(50, activation='relu', kernel_regularizer = l2(l2 = 0.01)))\n",
    "model_CNN6.add(layers.Dropout(0.3))\n",
    "model_CNN6.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "model_CNN6.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"Adam\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d63ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "history_CNN6 = model_CNN6.fit_generator(train_generator_arg_100, \n",
    "                                steps_per_epoch=25, \n",
    "                                epochs=15, \n",
    "                                validation_data=val_generator_arg_100, \n",
    "                                validation_steps=25)\n",
    "end = time.time()\n",
    "train_time = round(end-start, 0)\n",
    "savepath = \"./data/models/\"+model_name+\".h5\"\n",
    "model_CNN6.save(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e449589",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = make_results(results_df,image_size,train_time,model_name,history_CNN6, model_CNN6, test_images_100_arg, test_y)\n",
    "display(results_df)\n",
    "plot_results(history_CNN6, model_CNN6, test_images_100_arg, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7602158",
   "metadata": {},
   "source": [
    "argumented CNN 100 batch 64/32 Rmsprop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3e8544",
   "metadata": {},
   "source": [
    "##### 10) Augment CNN, shape 100 x 100 with reg and RMSprop optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f39a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Augmented CNN 100x100 with reg and RMSprop optimizer\"\n",
    "\n",
    "model_CNN8 = models.Sequential()\n",
    "model_CNN8.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(100 ,100, 3)))\n",
    "model_CNN8.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_CNN8.add(layers.Conv2D(64, (4, 4), activation='relu', kernel_regularizer = l2(l2 = 0.01)))\n",
    "model_CNN8.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_CNN8.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_CNN8.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_CNN8.add(layers.Flatten())\n",
    "model_CNN8.add(layers.Dense(50, activation='relu', kernel_regularizer = l2(l2 = 0.01)))\n",
    "model_CNN8.add(layers.Dropout(0.3))\n",
    "model_CNN8.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_CNN8.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0925ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "history_CNN8 = model_CNN8.fit_generator(train_generator_arg_100, \n",
    "                                steps_per_epoch=25, \n",
    "                                epochs=10, \n",
    "                                validation_data=val_generator_arg_100, \n",
    "                                validation_steps=25)\n",
    "\n",
    "end = time.time()\n",
    "train_time = round(end-start, 0)\n",
    "savepath = \"./data/models/\"+model_name+\".h5\"\n",
    "model_CNN8.save(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab6facd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = make_results(results_df,image_size,train_time,model_name,history_CNN8, model_CNN8, test_images_100_arg, test_y)\n",
    "display(results_df)\n",
    "plot_results(history_CNN8, model_CNN8, test_images_100_arg, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1109b5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test = model_CNN8.evaluate(test_images_100_arg, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a683ad",
   "metadata": {},
   "source": [
    "##### 11) Augment CNN, shape 100 x 100 with reg with additional regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d254602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Augmented CNN 100x100 with additional reg, increased training time\"\n",
    "model_CNN9 = models.Sequential()\n",
    "model_CNN9.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(100 ,100, 3)))\n",
    "model_CNN9.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_CNN9.add(layers.Conv2D(64, (4, 4), activation='relu'))\n",
    "model_CNN9.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_CNN9.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_CNN9.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_CNN9.add(layers.Flatten())\n",
    "model_CNN9.add(layers.Dense(50, activation='relu', kernel_regularizer = l2(l2 = 0.01)))\n",
    "model_CNN9.add(layers.Dropout(0.3))\n",
    "model_CNN9.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_CNN9.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c0057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "history_CNN9 = model_CNN9.fit_generator(train_generator_arg_100, \n",
    "                                steps_per_epoch=25, \n",
    "                                epochs=30, \n",
    "                                validation_data=val_generator_arg_100, \n",
    "                                validation_steps=25)\n",
    "\n",
    "end = time.time()\n",
    "train_time = round(end-start, 0)\n",
    "savepath = \"./data/models/\"+model_name+\".h5\"\n",
    "model_CNN9.save(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d70346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test = model_CNN9.evaluate(test_images_100_arg, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b8567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = make_results(results_df,image_size,train_time,model_name,history_CNN9, model_CNN9, test_images_100_arg, test_y)\n",
    "display(results_df)\n",
    "plot_results(history_CNN9, model_CNN9, test_images_100_arg, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4826e1f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b97e42d0",
   "metadata": {},
   "source": [
    "##### 12) Pre-trained Augmented CNN 100x100 frozen layer VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b215fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Pre-trained Augmented CNN 100x100 frozen layer VGG16, batch 92\"\n",
    "\n",
    "base_model_cnn = VGG16(\n",
    "        weights='imagenet',\n",
    "        include_top=False, \n",
    "        input_shape=(100,100,3))\n",
    "# Freeze VGG layer\n",
    "base_model_cnn.trainable = False\n",
    "model_new7 = models.Sequential()\n",
    "model_new7.add(base_model_cnn)\n",
    "model_new7.add(layers.Flatten())\n",
    "model_new7.add(layers.Dropout(0.3))\n",
    "model_new7.add(layers.Dense(64, activation=\"relu\", kernel_regularizer = l2(l2 = 0.01)))\n",
    "model_new7.add(layers.Dropout(0.3))\n",
    "model_new7.add(layers.Dense(1,activation=\"sigmoid\"))\n",
    "model_new7.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=\"adam\",\n",
    "    metrics=['accuracy'])\n",
    "start = time.time()\n",
    "history__new7 = model_new7.fit_generator(train_generator_arg_100, \n",
    "                                steps_per_epoch=25, \n",
    "                                epochs=10, \n",
    "                                validation_data=val_generator_arg_100, \n",
    "                                validation_steps=25)\n",
    "end = time.time()\n",
    "train_time = round(end-start, 0)\n",
    "savepath = \"./data/models/\"+model_name+\".h5\"\n",
    "model_new7.save(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b613ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_df = make_results(results_df,image_size,train_time,model_name,history__new7, model_new7, test_images_100_arg, test_y)\n",
    "display(results_df)\n",
    "plot_results(history__new7, model_new7, test_images_100_arg, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8573a3b0",
   "metadata": {},
   "source": [
    "##### 12) Pre-trained Augmented CNN 100x100 frozen layer VGG16 batch 64/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fb3de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (100,100)\n",
    "train_datagen_arg_100 = ImageDataGenerator(rescale=1./255, \n",
    "                                   rotation_range=10, \n",
    "                                   width_shift_range=0.2, \n",
    "                                   height_shift_range=0.2, \n",
    "                                   shear_range=0.2, \n",
    "                                   vertical_flip=True)\n",
    "test_generator_arg_100 = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_folder, \n",
    "        target_size=image_size, \n",
    "        batch_size = test_img_number,\n",
    "        class_mode='binary') \n",
    "\n",
    "# get all the data in the directory split/validation, and reshape them\n",
    "val_generator_arg_100 = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_folder, \n",
    "        target_size=image_size,\n",
    "        batch_size = 24,\n",
    "        class_mode='binary',\n",
    "        shuffle = True)\n",
    "\n",
    "# get all the data in the directory split/train , and reshape them\n",
    "train_generator_arg_100 = train_datagen_arg_100.flow_from_directory(\n",
    "        train_folder, target_size=image_size,\n",
    "        batch_size = 64, class_mode='binary',\n",
    "        shuffle = True)\n",
    "test_images, test_labels = next(test_generator_arg_100)\n",
    "test_y = np.reshape(test_labels[:,], (test_img_number,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c548ece",
   "metadata": {},
   "source": [
    "##### 13) Pre-trained Augmented CNN 100x100 frozen layer VGG16 with class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58f4864",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Pre-trained Augmented CNN 100x100 frozen layer VGG16 with weights\"\n",
    "\n",
    "base_model_cnn = VGG16(\n",
    "        weights='imagenet',\n",
    "        include_top=False, \n",
    "        input_shape=(100,100,3))\n",
    "# Freeze VGG layer\n",
    "base_model_cnn.trainable = False\n",
    "model_new4 = models.Sequential()\n",
    "model_new4.add(base_model_cnn)\n",
    "model_new4.add(layers.Flatten())\n",
    "model_new4.add(layers.Dense(64, activation=\"relu\", kernel_regularizer = l2(l2 = 0.01)))\n",
    "model_new4.add(layers.Dropout(0.3))\n",
    "model_new4.add(layers.Dense(1,activation=\"sigmoid\"))\n",
    "model_new4.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=\"adam\",\n",
    "    metrics=['accuracy'])\n",
    "start = time.time()\n",
    "history__new4 = model_new4.fit_generator(train_generator_arg_100, \n",
    "                                steps_per_epoch=25, \n",
    "                                epochs=10, \n",
    "                                validation_data=val_generator_arg_100, \n",
    "                                validation_steps=25, class_weight = {0: 2, 1: 1})\n",
    "end = time.time()\n",
    "train_time = round(end-start, 0)\n",
    "savepath = \"./data/models/\"+model_name+\".h5\"\n",
    "model_new4.save(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399f5cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = make_results(results_df,image_size,train_time,model_name,history__new4, model_new4, test_images_100_arg, test_y)\n",
    "display(results_df)\n",
    "plot_results(history__new4, model_new4, test_images_100_arg, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0f3013",
   "metadata": {},
   "source": [
    "##### 14) Pre-trained Augmented CNN 100x100 frozen layer VGG16 with class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376c7b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen_arg_100 = ImageDataGenerator(rescale=1./255, \n",
    "                                   rotation_range=20, \n",
    "                                   width_shift_range=0.2, \n",
    "                                   height_shift_range=0.2, \n",
    "                                   shear_range=0.2, \n",
    "                                   vertical_flip=True)\n",
    "test_generator_arg_100 = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_folder, \n",
    "        target_size=(100, 100), \n",
    "        batch_size = test_img_number,\n",
    "        class_mode='binary') \n",
    "\n",
    "# get all the data in the directory split/validation, and reshape them\n",
    "val_generator_arg_100 = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_folder, \n",
    "        target_size=(100, 100),\n",
    "        batch_size = 10,\n",
    "        class_mode='binary',\n",
    "        shuffle = True)\n",
    "\n",
    "# get all the data in the directory split/train , and reshape them\n",
    "train_generator_arg_100 = train_datagen_arg_100.flow_from_directory(\n",
    "        train_folder, target_size=(100, 100),\n",
    "        batch_size = 64, class_mode='binary',\n",
    "        shuffle = True)\n",
    "test_images, test_labels = next(test_generator_arg_100)\n",
    "test_y = np.reshape(test_labels[:,], (test_img_number,1))\n",
    "\n",
    "\n",
    "model_name = \"Pre-trained Augmented CNN 100x100 frozen layer VGG16\"\n",
    "\n",
    "base_model_cnn = VGG16(\n",
    "        weights='imagenet',\n",
    "        include_top=False, \n",
    "        input_shape=(100,100,3))\n",
    "# Freeze VGG layer\n",
    "base_model_cnn.trainable = False\n",
    "\n",
    "model_new6 = models.Sequential()\n",
    "model_new6.add(base_model_cnn)\n",
    "model_new6.add(layers.Flatten())\n",
    "model_new6.add(layers.Dense(64, activation=\"relu\", kernel_regularizer = l2(l2 = 0.01)))\n",
    "model_new6.add(layers.Dropout(0.2))\n",
    "model_new6.add(layers.Dense(1,activation=\"sigmoid\"))\n",
    "model_new6.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=\"adam\",\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "history__new6 = model_new6.fit_generator(train_generator_arg_100, \n",
    "                                steps_per_epoch=25, \n",
    "                                epochs=10, \n",
    "                                validation_data=val_generator_arg_100, \n",
    "                                validation_steps=25)\n",
    "end = time.time()\n",
    "train_time = round(end-start, 0)\n",
    "\n",
    "results_df = make_results(results_df,image_size,train_time,model_name,history__new6, model_new6, test_images, test_y)\n",
    "display(results_df)\n",
    "plot_results(history__new6, model_new6, test_images, test_y)\n",
    "savepath = \"./data/models/\"+model_name+\".h5\"\n",
    "model_new6.save(savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feed5f3c",
   "metadata": {},
   "source": [
    "##### 15) Pre-trained Augmented CNN 224x224 with MobileNetV2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c74269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen_arg_100 = ImageDataGenerator(rescale=1./255, \n",
    "                                   rotation_range=20, \n",
    "                                   width_shift_range=0.2, \n",
    "                                   height_shift_range=0.2, \n",
    "                                   shear_range=0.2, \n",
    "                                   vertical_flip=True)\n",
    "test_generator_arg_100 = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_folder, \n",
    "        target_size=(224, 224), \n",
    "        batch_size = test_img_number,\n",
    "        class_mode='binary') \n",
    "\n",
    "# get all the data in the directory split/validation, and reshape them\n",
    "val_generator_arg_100 = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_folder, \n",
    "        target_size=(224, 224),\n",
    "        batch_size = 10,\n",
    "        class_mode='binary',\n",
    "        shuffle = True)\n",
    "\n",
    "# get all the data in the directory split/train , and reshape them\n",
    "train_generator_arg_100 = train_datagen_arg_100.flow_from_directory(\n",
    "        train_folder, target_size=(224, 224),\n",
    "        batch_size = 64, class_mode='binary',\n",
    "        shuffle = True)\n",
    "test_images, test_labels = next(test_generator_arg_100)\n",
    "test_y = np.reshape(test_labels[:,], (test_img_number,1))\n",
    "\n",
    "\n",
    "model_name = \"Pre-trained Augmented CNN 224x224 frozen layer MobileNetV2\"\n",
    "\n",
    "base_model_cnn = MobileNetV2(weights='imagenet',\n",
    "        include_top=False, \n",
    "        input_shape=(224,224,3))\n",
    "        \n",
    "# Freeze VGG layer\n",
    "base_model_cnn.trainable = False\n",
    "\n",
    "model_new10 = models.Sequential()\n",
    "model_new10.add(base_model_cnn)\n",
    "model_new10.add(layers.Flatten())\n",
    "model_new10.add(layers.Dense(64, activation=\"relu\", kernel_regularizer = l2(l2 = 0.01)))\n",
    "model_new10.add(layers.Dropout(0.2))\n",
    "model_new10.add(layers.Dense(1,activation=\"sigmoid\"))\n",
    "model_new10.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=\"adam\",\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "history__new10 = model_new10.fit_generator(train_generator_arg_100, \n",
    "                                steps_per_epoch=25, \n",
    "                                epochs=14, \n",
    "                                validation_data=val_generator_arg_100, \n",
    "                                validation_steps=25)\n",
    "end = time.time()\n",
    "train_time = round(end-start, 0)\n",
    "\n",
    "results_df = make_results(results_df,image_size,train_time,model_name,history__new10, model_new10, test_images, test_y)\n",
    "display(results_df)\n",
    "plot_results(history__new10, model_new10, test_images, test_y)\n",
    "savepath = \"./data/models/\"+model_name+\".h5\"\n",
    "model_new10.save(savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e3881d",
   "metadata": {},
   "source": [
    "##### 16) Pre-trained Augmented CNN 224x224 with VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a80774",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen_arg_100 = ImageDataGenerator(rescale=1./255, \n",
    "                                   rotation_range=20, \n",
    "                                   width_shift_range=0.2, \n",
    "                                   height_shift_range=0.2, \n",
    "                                   shear_range=0.2, \n",
    "                                   vertical_flip=True)\n",
    "test_generator_arg_100 = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_folder, \n",
    "        target_size=(224, 224), \n",
    "        batch_size = test_img_number,\n",
    "        class_mode='binary') \n",
    "\n",
    "# get all the data in the directory split/validation, and reshape them\n",
    "val_generator_arg_100 = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_folder, \n",
    "        target_size=(224, 224),\n",
    "        batch_size = 16,\n",
    "        class_mode='binary',\n",
    "        shuffle = True)\n",
    "\n",
    "# get all the data in the directory split/train , and reshape them\n",
    "train_generator_arg_100 = train_datagen_arg_100.flow_from_directory(\n",
    "        train_folder, target_size=(224, 224),\n",
    "        batch_size = 64, class_mode='binary',\n",
    "        shuffle = True)\n",
    "test_images, test_labels = next(test_generator_arg_100)\n",
    "test_y = np.reshape(test_labels[:,], (test_img_number,1))\n",
    "\n",
    "\n",
    "model_name = \"Pre-trained Augmented CNN 224x224 frozen layer VGG16\"\n",
    "\n",
    "base_model_cnn = VGG16(\n",
    "        weights='imagenet',\n",
    "        include_top=False, \n",
    "        input_shape=(224,224,3))\n",
    "# Freeze VGG layer\n",
    "base_model_cnn.trainable = False\n",
    "\n",
    "model_new6 = models.Sequential()\n",
    "model_new6.add(base_model_cnn)\n",
    "model_new6.add(layers.Flatten())\n",
    "model_new6.add(layers.Dense(64, activation=\"relu\", kernel_regularizer = l2(l2 = 0.01)))\n",
    "model_new6.add(layers.Dropout(0.2))\n",
    "model_new6.add(layers.Dense(1,activation=\"sigmoid\"))\n",
    "model_new6.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=\"adam\",\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "history__new6 = model_new6.fit_generator(train_generator_arg_100, \n",
    "                                steps_per_epoch=25, \n",
    "                                epochs=10, \n",
    "                                validation_data=val_generator_arg_100, \n",
    "                                validation_steps=25)\n",
    "end = time.time()\n",
    "train_time = round(end-start, 0)\n",
    "\n",
    "results_df = make_results(results_df,image_size,train_time,model_name,history__new6, model_new6, test_images, test_y)\n",
    "display(results_df)\n",
    "plot_results(history__new6, model_new6, test_images, test_y)\n",
    "savepath = \"./data/models/\"+model_name+\".h5\"\n",
    "model_new6.save(savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bc017d",
   "metadata": {},
   "source": [
    "##### 17) Pre-trained Augmented CNN 200x200 frozen layer VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6ff78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (200,200)\n",
    "train_datagen_arg_100 = ImageDataGenerator(rescale=1./255, \n",
    "                                   rotation_range=20, \n",
    "                                   width_shift_range=0.2, \n",
    "                                   height_shift_range=0.2, \n",
    "                                   shear_range=0.2, \n",
    "                                   vertical_flip=True)\n",
    "test_generator_arg_100 = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_folder, \n",
    "        target_size=image_size, \n",
    "        batch_size = test_img_number,\n",
    "        class_mode='binary') \n",
    "\n",
    "# get all the data in the directory split/validation, and reshape them\n",
    "val_generator_arg_100 = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_folder, \n",
    "        target_size=image_size,\n",
    "        batch_size = 16,\n",
    "        class_mode='binary',\n",
    "        shuffle = True)\n",
    "\n",
    "# get all the data in the directory split/train , and reshape them\n",
    "train_generator_arg_100 = train_datagen_arg_100.flow_from_directory(\n",
    "        train_folder, target_size=image_size,\n",
    "        batch_size = 64, class_mode='binary',\n",
    "        shuffle = True)\n",
    "test_images, test_labels = next(test_generator_arg_100)\n",
    "test_y = np.reshape(test_labels[:,], (test_img_number,1))\n",
    "\n",
    "\n",
    "model_name = \"Pre-trained Augmented CNN 200x200 frozen layer VGG16\"\n",
    "\n",
    "base_model_cnn = VGG16(\n",
    "        weights='imagenet',\n",
    "        include_top=False, \n",
    "        input_shape=(200,200,3))\n",
    "# Freeze VGG layer\n",
    "base_model_cnn.trainable = False\n",
    "\n",
    "model_new3 = models.Sequential()\n",
    "model_new3.add(base_model_cnn)\n",
    "model_new3.add(layers.Flatten())\n",
    "model_new3.add(layers.Dense(64, activation=\"relu\", kernel_regularizer = l2(l2 = 0.01)))\n",
    "model_new3.add(layers.Dropout(0.2))\n",
    "model_new3.add(layers.Dense(1,activation=\"sigmoid\"))\n",
    "model_new3.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=\"adam\",\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "history__new3 = model_new3.fit_generator(train_generator_arg_100, \n",
    "                                steps_per_epoch=25, \n",
    "                                epochs=10, \n",
    "                                validation_data=val_generator_arg_100, \n",
    "                                validation_steps=25)\n",
    "end = time.time()\n",
    "train_time = round(end-start, 0)\n",
    "\n",
    "results_df = make_results(results_df,image_size,train_time,model_name,history__new3, model_new3, test_images, test_y)\n",
    "display(results_df)\n",
    "plot_results(history__new3, model_new3, test_images, test_y)\n",
    "model_new3.save('data/models/model_new6.h5')\n",
    "savepath = \"./data/models/\"+model_name+\".h5\"\n",
    "model_new3.save(savepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a907c64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36ddb7d",
   "metadata": {},
   "source": [
    "##### Fine tuning\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2265e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finall model has resolution 224x224, lets generate images in required resolution for this model:\n",
    "\n",
    "test_generator_arg_100 = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_folder, \n",
    "        target_size=(224, 224), \n",
    "        batch_size = test_img_number,\n",
    "        class_mode='binary') \n",
    "test_images, test_labels = next(test_generator_arg_100)\n",
    "test_y = np.reshape(test_labels[:,], (test_img_number,1))\n",
    "\n",
    "# Define best model\n",
    "best_model = model_new10\n",
    "test_images_in_resolution = test_images\n",
    "test_images_labels = test_y\n",
    "predictions = best_model.predict(test_images_in_resolution)\n",
    "predictions_base = [1 if x > 0.5 else 0 for x in predictions]\n",
    "test_accuracy_base = round(accuracy_score(test_images_labels, predictions_base),4)\n",
    "test_recall_base = round(recall_score(test_images_labels, predictions_base),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa34e057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop with changing prediction bondaries\n",
    "list_of_thresholds = list(np.linspace(0.2, 0.8, 13))\n",
    "list_of_options=[]\n",
    "for threshold in list_of_thresholds:\n",
    "    prediction_new = [1 if x > threshold else 0 for x in predictions]\n",
    "    test_accuracy = round(accuracy_score(test_images_labels, prediction_new),4)\n",
    "    test_recall = round(recall_score(test_images_labels, prediction_new),4)\n",
    "    list_of_options.append((threshold, test_accuracy, test_recall))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c415127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base model predictions\n",
    "print(\"Optimization focusen on accuracy\")\n",
    "print(f\"Model accuracy {test_accuracy_base}. Model recall {test_recall_base}\")\n",
    "\n",
    "\n",
    "# Best prediction threshold for accuracy\n",
    "threshold_acc = sorted(list_of_options, key = lambda x: x[1], reverse = True)[0]\n",
    "print(\"Optimization focusen on accuracy\")\n",
    "print(f\"Model accuracy {threshold_acc[1]}. Model recall {threshold_acc[2]}\")\n",
    "\n",
    "\n",
    "# Best prediction threshold for recall\n",
    "threshold_recall = sorted(list_of_options, key = lambda x: x[2], reverse = True)[0]\n",
    "print(\"Optimization focusen on recall\")\n",
    "print(f\"Model accuracy {threshold_recall[1]}. Model recall {threshold_recall[2]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc57e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dubious cases removal\n",
    "lower_border = 0.25\n",
    "upper_border = 0.55\n",
    "new_list = zip (test_images_labels, predictions)\n",
    "new_predictions = [item for item in new_list if ((item[1] > upper_border) or (item[1] < lower_border))]\n",
    "new_test_set = [new_prediction[0] for new_prediction in new_predictions]\n",
    "new_predictions_after = [1 if x[1] > 0.5 else 0 for x in new_predictions]\n",
    "new_accuracy = round(accuracy_score(new_test_set, new_predictions_after),4)\n",
    "new_recall = round(recall_score(new_test_set, new_predictions_after),4)\n",
    "print(f\"Doubious cases investigation:\")\n",
    "print(f\"Doubious cases that were removed: {round((1-len(new_predictions)/len(predictions))*100,2 )}%\")\n",
    "print(f\"Model accuracy after removal {new_accuracy}. Model recall after removal {new_recall}\")\n",
    "confusion_mtx = confusion_matrix(new_test_set, new_predictions_after)\n",
    "cm = plot_confusion_matrix(confusion_mtx, classes = [\"normal\", \"pneumonia\"], normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3468e98",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "---\n",
    "Based on results our finall model will be: \"Pre-trained Augmented CNN 224x224 frozen layer MobileNetV2\"\n",
    "\n",
    "With the following parameters after tuning:\n",
    "\n",
    "Accuracy - 0.9519\n",
    "\n",
    "Recall - 0.9769\n",
    "\n",
    "Because of the following reasons: \n",
    "\n",
    "1) It satisfy requirements on recall (higher 0.95).\n",
    "\n",
    "2) It has high accuracy. \n",
    "\n",
    "Another solution for this problem might be identify cases that has probability between classes and send it to firther investigation by takeholder.\n",
    "We are interested in maximizing racall (min FN) so we will remove prediction not equally from decision boundary, but we will drop cases with probabiblity 0.25-0.55 \n",
    "This approach allows us to get accuracy 0.9726 and recall 0.992\n",
    "\n",
    "Overall, this data tells us that current X-ray have enought information so we can be sure that each patient will be treated well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3a5b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
