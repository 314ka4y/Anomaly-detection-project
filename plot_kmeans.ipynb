{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# k-means\n",
    "\n",
    "This example uses $k$-means clustering for time series. Three variants of\n",
    "the algorithm are available: standard\n",
    "Euclidean $k$-means, DBA-$k$-means (for DTW Barycenter\n",
    "Averaging [1])\n",
    "and Soft-DTW $k$-means [2].\n",
    "\n",
    "In the figure below, each row corresponds to the result of a different\n",
    "clustering. In a row, each sub-figure corresponds to a cluster.\n",
    "It represents the set\n",
    "of time series from the training set that were assigned to the considered\n",
    "cluster (in black) as well as the barycenter of the cluster (in red).\n",
    "\n",
    "## A note on pre-processing\n",
    "\n",
    "In this example, time series are preprocessed using\n",
    "`TimeSeriesScalerMeanVariance`. This scaler is such that each output time\n",
    "series has zero mean and unit variance.\n",
    "The assumption here is that the range of a given time series is uninformative\n",
    "and one only wants to compare shapes in an amplitude-invariant manner (when\n",
    "time series are multivariate, this also rescales all modalities such that there\n",
    "will not be a single modality responsible for a large part of the variance).\n",
    "This means that one cannot scale barycenters back to data range because each\n",
    "time series is scaled independently and there is hence no such thing as an\n",
    "overall data range.\n",
    "\n",
    "[1] F. Petitjean, A. Ketterlin & P. Gancarski. A global averaging method for dynamic time warping, with applications to clustering. Pattern Recognition, Elsevier, 2011, Vol. 44, Num. 3, pp. 678-693\n",
    "[2] M. Cuturi, M. Blondel \"Soft-DTW: a Differentiable Loss Function for Time-Series,\" ICML 2017.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Romain Tavenard\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.datasets import CachedDatasets\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance, \\\n",
    "    TimeSeriesResampler\n",
    "\n",
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "X_train, y_train, X_test, y_test = CachedDatasets().load_dataset(\"Trace\")\n",
    "X_train = X_train[y_train < 4]  # Keep first 3 classes\n",
    "numpy.random.shuffle(X_train)\n",
    "# Keep only 50 time series\n",
    "X_train = TimeSeriesScalerMeanVariance().fit_transform(X_train[:50])\n",
    "# Make time series shorter\n",
    "X_train = TimeSeriesResampler(sz=40).fit_transform(X_train)\n",
    "sz = X_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.70284807],\n",
       "        [ 0.67041062],\n",
       "        [ 0.66094803],\n",
       "        ...,\n",
       "        [ 0.58290225],\n",
       "        [ 0.5847045 ],\n",
       "        [ 0.59973054]],\n",
       "\n",
       "       [[ 0.78424784],\n",
       "        [ 0.76968207],\n",
       "        [ 0.73637576],\n",
       "        ...,\n",
       "        [ 0.79215738],\n",
       "        [ 0.77039311],\n",
       "        [ 0.78639174]],\n",
       "\n",
       "       [[-1.45424119],\n",
       "        [-1.47859826],\n",
       "        [-1.50492559],\n",
       "        ...,\n",
       "        [ 0.72844694],\n",
       "        [ 0.72533128],\n",
       "        [ 0.7094401 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.75458352],\n",
       "        [ 0.78165687],\n",
       "        [ 0.80198359],\n",
       "        ...,\n",
       "        [ 0.74927489],\n",
       "        [ 0.7479381 ],\n",
       "        [ 0.74485583]],\n",
       "\n",
       "       [[-1.38201243],\n",
       "        [-1.35633753],\n",
       "        [-1.37303456],\n",
       "        ...,\n",
       "        [ 0.76888577],\n",
       "        [ 0.81197286],\n",
       "        [ 0.83448894]],\n",
       "\n",
       "       [[ 0.66455793],\n",
       "        [ 0.56782604],\n",
       "        [ 0.65111839],\n",
       "        ...,\n",
       "        [ 0.55524164],\n",
       "        [ 0.55725016],\n",
       "        [ 0.56296336]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Euclidean k-means\n",
    "print(\"Euclidean k-means\")\n",
    "km = TimeSeriesKMeans(n_clusters=3, verbose=True, random_state=seed)\n",
    "y_pred = km.fit_predict(X_train)\n",
    "\n",
    "plt.figure()\n",
    "for yi in range(3):\n",
    "    plt.subplot(3, 3, yi + 1)\n",
    "    for xx in X_train[y_pred == yi]:\n",
    "        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n",
    "    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n",
    "    plt.xlim(0, sz)\n",
    "    plt.ylim(-4, 4)\n",
    "    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n",
    "             transform=plt.gca().transAxes)\n",
    "    if yi == 1:\n",
    "        plt.title(\"Euclidean $k$-means\")\n",
    "\n",
    "# DBA-k-means\n",
    "print(\"DBA k-means\")\n",
    "dba_km = TimeSeriesKMeans(n_clusters=3,\n",
    "                          n_init=2,\n",
    "                          metric=\"dtw\",\n",
    "                          verbose=True,\n",
    "                          max_iter_barycenter=10,\n",
    "                          random_state=seed)\n",
    "y_pred = dba_km.fit_predict(X_train)\n",
    "\n",
    "for yi in range(3):\n",
    "    plt.subplot(3, 3, 4 + yi)\n",
    "    for xx in X_train[y_pred == yi]:\n",
    "        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n",
    "    plt.plot(dba_km.cluster_centers_[yi].ravel(), \"r-\")\n",
    "    plt.xlim(0, sz)\n",
    "    plt.ylim(-4, 4)\n",
    "    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n",
    "             transform=plt.gca().transAxes)\n",
    "    if yi == 1:\n",
    "        plt.title(\"DBA $k$-means\")\n",
    "\n",
    "# Soft-DTW-k-means\n",
    "print(\"Soft-DTW k-means\")\n",
    "sdtw_km = TimeSeriesKMeans(n_clusters=3,\n",
    "                           metric=\"softdtw\",\n",
    "                           metric_params={\"gamma\": .01},\n",
    "                           verbose=True,\n",
    "                           random_state=seed)\n",
    "y_pred = sdtw_km.fit_predict(X_train)\n",
    "\n",
    "for yi in range(3):\n",
    "    plt.subplot(3, 3, 7 + yi)\n",
    "    for xx in X_train[y_pred == yi]:\n",
    "        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n",
    "    plt.plot(sdtw_km.cluster_centers_[yi].ravel(), \"r-\")\n",
    "    plt.xlim(0, sz)\n",
    "    plt.ylim(-4, 4)\n",
    "    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n",
    "             transform=plt.gca().transAxes)\n",
    "    if yi == 1:\n",
    "        plt.title(\"Soft-DTW $k$-means\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - tslearn\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    tslearn-0.5.2              |   py38hbe852b5_1         420 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         420 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  tslearn            conda-forge/osx-64::tslearn-0.5.2-py38hbe852b5_1\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "tslearn-0.5.2        | 420 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
